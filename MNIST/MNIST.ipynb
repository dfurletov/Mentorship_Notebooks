{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG9CWTs7Vdjg",
        "colab_type": "text"
      },
      "source": [
        "# Reading Numbers Using Keras and their training data\n",
        "### Imports for keras and others:\n",
        "### Read data for training and testing from keras dataset:\n",
        "### Run very bottom block once to get images and colors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIxZZzELVIF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import resource\n",
        "def getMemUse():\n",
        "    return \" mem use: {:.5f}MB \".format(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss*0.000001)\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten\n",
        "from tensorflow.keras.layers import Dropout, Activation, Conv2D, MaxPooling2D\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import random\n",
        "\n",
        "red_mask = (0.9,0.2,0.2)\n",
        "green_mask = (0.2,0.9,0.2)\n",
        "blue_mask = (0.2,0.2,0.9)\n",
        "colors = {0:red_mask, 1:blue_mask, 2:green_mask}\n",
        "colls = {0:\"red\", 1:\"blue\", 2:\"green\"}\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe1wf4JxVnFq",
        "colab_type": "text"
      },
      "source": [
        "### Normalize inputs from 0-255 to 0-1 as a float point:\n",
        "### Change correct outputs to a 10 size categorical numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZhtJFqbVo1c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "c950cef7-f844-4c87-dae5-03b6aad0f370"
      },
      "source": [
        "# normalization by dividing by 255 seems to work well\n",
        "# X_train = keras.utils.normalize(X_train, axis=1)\n",
        "# X_test = keras.utils.normalize(X_test, axis=1)\n",
        "\n",
        "# datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "# train_it = datagen.flow_from_directory('images/train/', class_mode='categorical', target_size=(28,28), batch_size=64)\n",
        "# test_it = datagen.flow_from_directory('images/test/', class_mode='categorical', target_size=(28,28), batch_size=64)\n",
        "\n",
        "X_train = np.zeros([60000,28,28,3])\n",
        "X_test = np.zeros([10000,28,28,3])\n",
        "\n",
        "Y_train = np.zeros([60000,10])\n",
        "Y_test = np.zeros([10000,10])\n",
        "\n",
        "Y_train_color = np.zeros([60000,3])\n",
        "Y_test_color = np.zeros([10000,3])\n",
        "for i in range(len(X_train)):\n",
        "    name = \"images/train/image{:05d}.npy\".format(i)\n",
        "    data = np.load(name, allow_pickle=True)\n",
        "    X_train[i] = data[0]\n",
        "    Y_train[i] = data[1]\n",
        "    Y_train_color[i] = data[2]\n",
        "    if i % 1000 == 0:\n",
        "        print(\"\\rreading training data: {:3.2f}% {} \".format((i/len(X_train))*100,getMemUse()), end='')\n",
        "print(\"\\rreading training data: 100% {} \".format(getMemUse()))\n",
        "for i in range(len(X_test)):\n",
        "    name = \"images/test/image{:05d}.npy\".format(i)\n",
        "    data = np.load(name, allow_pickle=True)\n",
        "    X_test[i] = data[0]\n",
        "    Y_test[i] = data[1]\n",
        "    Y_test_color[i] = data[2]\n",
        "    if i % 1000 == 0:\n",
        "        print(\"\\rreading testing data: {:3.2f}% {} \".format((i/len(X_test))*100,getMemUse()), end='')\n",
        "print(\"\\rreading testing data: 100% {} \".format(getMemUse()))\n",
        "    \n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)\n",
        "\n",
        "print(Y_train_color.shape)\n",
        "print(Y_test_color.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reading training data: 100%  mem use: 7.22713MB  \n",
            "reading testing data: 100%  mem use: 7.22713MB  \n",
            "(60000, 28, 28, 3)\n",
            "(10000, 28, 28, 3)\n",
            "(60000, 10)\n",
            "(10000, 10)\n",
            "(60000, 3)\n",
            "(10000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCL-Ec4KVsqi",
        "colab_type": "text"
      },
      "source": [
        "### Create a sequential model and add neurons/nodes: choose\n",
        "- First - simple\n",
        "- Second - complex\n",
        "- Third - Differenciate color too"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07iAPIhIVuyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape=(28,28,3)))\n",
        "\n",
        "model.add(Flatten());\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpXWmLXJVw5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape=(28,28,1)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDYoGXmzVyaa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b3a2a31d-860a-4c8e-cb8a-fb820564806b"
      },
      "source": [
        "# Legit no clue what this does, but it works...\n",
        "# https://www.pyimagesearch.com/2018/06/04/keras-multiple-outputs-and-multiple-losses/\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Lambda\n",
        "def build_category_branch(inputs):\n",
        "    # utilize a lambda layer to convert the 3 channel input to a\n",
        "    # grayscale representation\n",
        "    x = Lambda(lambda c: tf.image.rgb_to_grayscale(c))(inputs)\n",
        "    # CONV => RELU => POOL\n",
        "    x = Conv2D(32, (3, 3), padding=\"same\",activation='relu')(x)\n",
        "    # x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "    x = MaxPooling2D(pool_size=(3, 3))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "        \n",
        "    # (CONV => RELU) * 2 => POOL\n",
        "    x = Conv2D(64, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "    x = Conv2D(64, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    # (CONV => RELU) * 2 => POOL\n",
        "    x = Conv2D(128, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "    x = Conv2D(128, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "        \n",
        "    x = Flatten()(x)\n",
        "    x = Dense(256)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(10)(x)\n",
        "    x = Activation(\"softmax\", name=\"category_output\")(x)\n",
        "    # return the category prediction sub-network\n",
        "    return x\n",
        "def build_color_branch(inputs):\n",
        "    # CONV => RELU => POOL\n",
        "    x = Conv2D(16, (3, 3), padding=\"same\")(inputs)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "    x = MaxPooling2D(pool_size=(3, 3))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    # CONV => RELU => POOL\n",
        "    x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    # CONV => RELU => POOL\n",
        "    x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(3)(x)\n",
        "    x = Activation(\"softmax\", name=\"color_output\")(x)\n",
        "    # return the color prediction sub-network\n",
        "    return x\n",
        "\n",
        "inputs = Input(shape=(28, 28, 3))\n",
        "categoryBranch = build_category_branch(inputs)\n",
        "colorBranch = build_color_branch(inputs)\n",
        "model = Model(inputs=inputs, outputs=[categoryBranch, colorBranch], name=\"num-color-tegorizer\")\n",
        "losses = {\n",
        "    \"category_output\": \"categorical_crossentropy\",\n",
        "    \"color_output\": \"categorical_crossentropy\",\n",
        "}\n",
        "lossWeights = {\"category_output\": 1.0, \"color_output\": 1.0}\n",
        "opt = keras.optimizers.Adam(lr=1e-3, decay=1e-3 / 5)\n",
        "model.compile(optimizer=opt, loss=losses, loss_weights=lossWeights, metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "H = model.fit(x=X_train, y={\"category_output\": Y_train, \"color_output\": Y_train_color}, \n",
        "              validation_data=(X_test, {\"category_output\": Y_test, \"color_output\": Y_test_color}),\n",
        "              epochs=5, verbose=1)\n",
        "print(H)\n",
        "# save to model.keras as h5\n",
        "model.save(\"model.keras\", save_format=\"h5\")\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"num-color-tegorizer\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 28, 28, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 28, 28, 1)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 28, 28, 32)   320         lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 28, 28, 32)   128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 9, 9, 32)     0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 9, 9, 32)     0           max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 9, 9, 64)     18496       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 9, 9, 64)     0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 28, 28, 16)   448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 9, 9, 64)     256         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 28, 28, 16)   0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 9, 9, 64)     36928       batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 28, 28, 16)   64          activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 9, 9, 64)     0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 9, 9, 16)     0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 9, 9, 64)     256         activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 9, 9, 16)     0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 4, 4, 64)     0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 9, 9, 32)     4640        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 4, 4, 64)     0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 9, 9, 32)     0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 4, 4, 128)    73856       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 9, 9, 32)     128         activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 4, 4, 128)    0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 32)     0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 4, 4, 128)    512         activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 4, 4, 32)     0           max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 4, 4, 128)    147584      batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 4, 4, 32)     9248        dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 4, 4, 128)    0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 4, 4, 32)     0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 4, 4, 128)    512         activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 4, 4, 32)     128         activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 2, 2, 128)    0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 2, 2, 32)     0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 2, 2, 128)    0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 2, 2, 32)     0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 512)          0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 128)          0           dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          131328      flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 128)          16512       flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 256)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 128)          0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 256)          1024        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 128)          512         activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 256)          0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 128)          0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           2570        dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 3)            387         dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "category_output (Activation)    (None, 10)           0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "color_output (Activation)       (None, 3)            0           dense_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 445,837\n",
            "Trainable params: 444,077\n",
            "Non-trainable params: 1,760\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2939 - category_output_loss: 0.2793 - color_output_loss: 0.0146 - category_output_accuracy: 0.9145 - color_output_accuracy: 0.9952 - val_loss: 0.0434 - val_category_output_loss: 0.0434 - val_color_output_loss: 1.6013e-05 - val_category_output_accuracy: 0.9859 - val_color_output_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0883 - category_output_loss: 0.0881 - color_output_loss: 2.3201e-04 - category_output_accuracy: 0.9729 - color_output_accuracy: 1.0000 - val_loss: 0.0447 - val_category_output_loss: 0.0447 - val_color_output_loss: 2.5467e-06 - val_category_output_accuracy: 0.9856 - val_color_output_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0624 - category_output_loss: 0.0623 - color_output_loss: 9.0843e-05 - category_output_accuracy: 0.9810 - color_output_accuracy: 1.0000 - val_loss: 0.0353 - val_category_output_loss: 0.0353 - val_color_output_loss: 5.0396e-07 - val_category_output_accuracy: 0.9888 - val_color_output_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0517 - category_output_loss: 0.0517 - color_output_loss: 3.7653e-05 - category_output_accuracy: 0.9843 - color_output_accuracy: 1.0000 - val_loss: 0.0234 - val_category_output_loss: 0.0234 - val_color_output_loss: 1.9966e-07 - val_category_output_accuracy: 0.9926 - val_color_output_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0427 - category_output_loss: 0.0427 - color_output_loss: 2.2340e-05 - category_output_accuracy: 0.9871 - color_output_accuracy: 1.0000 - val_loss: 0.0190 - val_category_output_loss: 0.0190 - val_color_output_loss: 3.1412e-08 - val_category_output_accuracy: 0.9938 - val_color_output_accuracy: 1.0000\n",
            "<tensorflow.python.keras.callbacks.History object at 0x7f44901d8da0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNlEXb6zV270",
        "colab_type": "text"
      },
      "source": [
        "### Run model training and save to \"test\" folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enliKSuXV3Q1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss_fn = keras.losses.categorical_crossentropy\n",
        "# optimizer = keras.optimizers.Adam()\n",
        "# metrics = [keras.metrics.Accuracy()]\n",
        "# model.compile(loss=loss_fn, optimizer=optimizer, metrics=metrics)\n",
        "# print(process.memory_info().rss)  # print(process.memory_info()[0]) # bytes\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, epochs=5, verbose=1)\n",
        "model.save(\"test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uonpkfDIV40T",
        "colab_type": "text"
      },
      "source": [
        "### Load and show score of \"test\" model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2CdaOgeV6ol",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "45d85906-94a5-4e0a-fb2d-5b53481cc951"
      },
      "source": [
        "model = tf.keras.models.load_model(\"model.keras\")\n",
        "score = model.evaluate(X_test, {\"category_output\": Y_test, \"color_output\": Y_test_color}, verbose=1)\n",
        "print(score)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0190 - category_output_loss: 0.0190 - color_output_loss: 3.1412e-08 - category_output_accuracy: 0.9938 - color_output_accuracy: 1.0000\n",
            "[0.019049840047955513, 0.019049804657697678, 3.141160220820893e-08, 0.9937999844551086, 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEWO2aAqV8FQ",
        "colab_type": "text"
      },
      "source": [
        "### Loop through the test list and show comparison of image and value guessed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtXNDpwDV9Z7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "outputId": "ab4e01f5-7e4d-4f38-be11-fb3dfad38ad5"
      },
      "source": [
        "predictions = model.predict(X_test)\n",
        "good_list = tuple(zip(X_test, predictions[0], predictions[1]))\n",
        "for (test, prediction, color) in good_list:\n",
        "    clear_output(wait=True)\n",
        "    print(np.argmax(prediction))\n",
        "    col = np.argmax(color)\n",
        "    if col == 0:\n",
        "        print(\"red\")\n",
        "    if col == 1:\n",
        "        print(\"blue\")\n",
        "    if col == 2:\n",
        "        print(\"green\")\n",
        "    test = np.reshape(test,(28,28,3))\n",
        "    plt.imshow(test)\n",
        "    plt.show()\n",
        "    time.sleep(1.5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "green\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-71fb507022b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "expz4F8dV-8g",
        "colab_type": "text"
      },
      "source": [
        "# Just for Randomizing image color\n",
        "### if you want to try, run after getting the data from mnist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pq56EVlhWCO2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "c4bb372a-bdb1-4b1d-dff9-15b7ca73be78"
      },
      "source": [
        "# colorize images\n",
        "\n",
        "random.seed()\n",
        "\n",
        "def apply_mask(img, mask):\n",
        "    for i, col in enumerate(img[:]):\n",
        "        for j, pixel in enumerate(col[:]):\n",
        "            if pixel[0] != 0.0:\n",
        "                img[i,j] = [pixel[0]*mask[0], pixel[1]*mask[1], pixel[2]*mask[2]]\n",
        "    return img\n",
        "\n",
        "! mkdir images\n",
        "! mkdir images/train\n",
        "! mkdir images/test\n",
        "\n",
        "# returns randomized color images and its solution\n",
        "def randomize_colors(data, data_sol, data_type):\n",
        "    data = data / 255.\n",
        "    data = np.expand_dims(data,3)\n",
        "    randomized_data = np.zeros([len(data), 28, 28, 3])\n",
        "    solution = np.zeros([len(data), len(colors)])\n",
        "    for i, img in enumerate(data):\n",
        "        img = np.concatenate((data[i], np.expand_dims(data[i][:,:,0], 2)), axis=2)\n",
        "        randomized_data[i] = np.concatenate((img, np.expand_dims(data[i][:,:,0], 2)), axis=2)\n",
        "        rand = random.randint(0,len(colors)-1)\n",
        "        randomized_data[i] = apply_mask(randomized_data[i], colors[rand])\n",
        "        solution[i,rand] = 1.\n",
        "        name = \"images/{}/image{:05d}\".format(data_type,i)\n",
        "        np.save(name,np.array((randomized_data[i], data_sol[i], solution[i]), dtype=object))\n",
        "        keras.preprocessing.image.save_img(name+\".png\",randomized_data[i])\n",
        "        if i % 1000 == 0:\n",
        "            print(\"\\r{:3.2f}% {} \".format((i/len(data))*100,getMemUse()), end='')\n",
        "    print(\"\\r100% {} \".format(getMemUse()))\n",
        "    return (randomized_data, solution)\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = keras.datasets.mnist.load_data()\n",
        "Y_train = keras.utils.to_categorical(Y_train, 10)\n",
        "Y_test = keras.utils.to_categorical(Y_test, 10)\n",
        "X_train, Y_train_color = randomize_colors(X_train,Y_train,\"train\")\n",
        "X_test, Y_test_color = randomize_colors(X_test,Y_test,\"test\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "100%  mem use: 1.86705MB  \n",
            "100%  mem use: 1.86705MB  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83NYLA8PWl5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}