{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Te6rdZgT5yAW"
   },
   "source": [
    "# Copy of Previous RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdsGeayZ523e"
   },
   "source": [
    "### Reminders:\n",
    "\n",
    "Read up on some of these:\n",
    "- https://machinelearningmastery.com/stateful-stateless-lstm-time-series-forecasting-python/\n",
    "- https://fairyonice.github.io/Stateful-LSTM-model-training-in-Keras.html \n",
    "- https://github.com/keras-team/keras/issues/5714\n",
    "- https://machinelearningmastery.com/use-different-batch-sizes-training-predicting-python-keras/\n",
    "\n",
    "###Shuffle Data!!!!!\n",
    "\n",
    "\"An issue with LSTMs is that they can easily overfit training data, reducing their predictive skill.\"\n",
    "https://machinelearningmastery.com/use-dropout-lstm-networks-time-series-forecasting/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ro1oh9-25xM9",
    "outputId": "e2638721-dec3-4b6c-9db0-df28d7fce705"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7yOaxkJ58hh"
   },
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5Lupm0J6Hre"
   },
   "source": [
    "## Do Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gE8NHB9v6IDc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas\n",
    "from matplotlib import pyplot as plt\n",
    "from math import isnan\n",
    "from scipy.stats import norm\n",
    "\n",
    "pandas.set_option('display.max_columns', None)\n",
    "np.set_printoptions(suppress=True, precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yhg_bSj36CSt"
   },
   "source": [
    "## Obtain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1LMf25vB5_vs"
   },
   "outputs": [],
   "source": [
    "# read data from drive\n",
    "# csv_train = pandas.read_csv(\"drive/MyDrive/first_10k.csv\")\n",
    "# csv_train = pandas.read_csv(\"first_10k.csv\")\n",
    "csv_train = pandas.read_csv(\"FDC_tracks.csv\") # n entries read how many\n",
    "# csv_train = pandas.read_csv(\"drive/MyDrive/FDC_tracks.csv\")\n",
    "unparsed_train = np.array(csv_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7L54wTFh-NGU"
   },
   "source": [
    "## Ragged Custom Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KoN7P86yCif6",
    "outputId": "b9ad9880-a607-4ac8-dd65-3e3a802f4a7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47.79000536345256, 47.85379805605636, 47.9992377193164, 0.0433333333333333, 96.0, 24.0, 343.50521373311966, 286.0835876464844, 8.505786274806298e-07, 361.0058481985338]\n",
      "[-47.79320886187116, -47.82910626759677, -47.970923331835934, 0.0100277003822788, 1.0, 1.0, 176.86502273229647, -77.795654296875, 7.068405941829982e-10, 0.2999999999999999]\n",
      "[55.89694660240736, 186.5701039032152, 142.7006206345797, 96.29041800810668]\n",
      "[-68.85007623607558, -121.16037940160004, -104.91556918573488, -119.24852892684449]\n"
     ]
    }
   ],
   "source": [
    "_max = [-1000 for i in range(10)]\n",
    "_min = [1000 for i in range(10)]\n",
    "for index,event in enumerate(unparsed_train):\n",
    "  lower = 67\n",
    "  for upper in range(lower+14, event.shape[0]+1, 14):\n",
    "    d = event[lower:upper]\n",
    "    d = np.append(d[:2],d[6:])\n",
    "    for a in range(len(d)):\n",
    "      if d[a] > _max[a]:\n",
    "        _max[a] = d[a]\n",
    "      if d[a] < _min[a]:\n",
    "        _min[a] = d[a]\n",
    "    lower = upper\n",
    "print(_max)\n",
    "print(_min)\n",
    "\n",
    "_TOF_max = [-1000 for i in range(4)]\n",
    "_TOF_min = [1000 for i in range(4)]\n",
    "for index,event in enumerate(unparsed_train):\n",
    "  TOF = event[59:67]\n",
    "  # print(TOF)\n",
    "  for a in range(4):\n",
    "    if TOF[a*2] > _TOF_max[a]:\n",
    "      _TOF_max[a] = TOF[a*2]\n",
    "    if TOF[a*2] < _TOF_min[a]:\n",
    "      _TOF_min[a] = TOF[a*2]\n",
    "print(_TOF_max)\n",
    "print(_TOF_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOfDY5F8yJyl"
   },
   "source": [
    "After trying out many different possibilities, I have found making a RaggedTensor is the way to make variable timesteps.\n",
    "\n",
    "Once you create a RaggedTensor ONLY FOR X DATA, you need to also add:\n",
    "\n",
    "ragged=True\n",
    "\n",
    "to the keras.Inputs() function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BfACUWvW-NGd"
   },
   "outputs": [],
   "source": [
    "glob_index = 2\n",
    "def ragged_parser(unparsed):\n",
    "  global _min, _max, glob_index\n",
    "  x_final = []\n",
    "  y_final = []\n",
    "  invCov_final = []\n",
    "  cov_final = []\n",
    "  for event in unparsed:\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    nEvent = event[0]     # all the data split into neat little arrays...\n",
    "    state = event[1:6]\n",
    "    coVar = event[6:31]\n",
    "    invCoVar = event[31:56]\n",
    "    goodnessOfFit = event[56:59]\n",
    "    TOF = event[59:67]\n",
    "\n",
    "    if goodnessOfFit[0]/float(goodnessOfFit[1]) > 5:\n",
    "      continue\n",
    "    if goodnessOfFit[2] > 0.1:   # Cutting if rms is too high\n",
    "      continue\n",
    "    hits = []\n",
    "    lower = 67\n",
    "    for upper in range(lower+14, event.shape[0]+1, 14): # to flip just go from end to 67 by -14 steps?\n",
    "\n",
    "      # hasNAN = False\n",
    "      # for val in event[lower:upper]:\n",
    "      #   if isnan(val):\n",
    "      #     hasNAN = True\n",
    "      # if not hasNAN:\n",
    "\n",
    "      if not isnan(event[lower]):            # Check if we are done with hits, because data is cut short, the rest will be nan\n",
    "        hit_data = event[lower:upper]                      # retrieving the hit\n",
    "        hit_data = np.append(hit_data[:2],hit_data[6:])    # cutting out the sin and cos data\n",
    "        for z in range(len(hit_data)):\n",
    "          hit_data[z] = (hit_data[z] - _min[z]) / (_max[z] - _min[z])    # we need to normalize the data; this can be moved to a lambda layer in the network if needed.\n",
    "        for i_TOF in range(4):\n",
    "          TOF[i_TOF*2] = (TOF[i_TOF*2] - _TOF_min[i_TOF]) / (_TOF_max[i_TOF] - _TOF_min[i_TOF])\n",
    "        hit_data = np.append(hit_data,TOF)\n",
    "        hits.append(np.ndarray.tolist(hit_data))       # we want it as a list to convert to RaggedTensor later; last time I checked it didnt work with array.\n",
    "      lower = upper\n",
    "    for i in range(len(hits)):   # this could be simplified to just: \"x = hits\" if im not mistaken...\n",
    "      x.append(hits[i])          # however we might need to add y.append(hits[i+1]) for later testing so leaving it like this for now...\n",
    "    y = np.ndarray.tolist(state)   # technically not needed, can be removed later... at first I thought i need to pass RaggedTensor labels, but that is not the case.\n",
    "    x_final.append(x)          # want x_final to be shape (event, hit, 10) as a list\n",
    "#     y_final.append(y)          # want y_final to be shape (event, 5)       as a np.array\n",
    "    y_final.append(y[glob_index])          # want y_final to be shape (event, 5)       as a np.array\n",
    "    invCov_final.append(invCoVar[:])  # want other_f to be shape (event, 25)      as a np.array\n",
    "    cov_final.append(coVar[:])\n",
    "  x_final = tf.ragged.constant(x_final)   # convert list to RaggedTensor because timesteps (number of hits) are variable between events\n",
    "  y_final = np.array(y_final)\n",
    "  invCov_final = np.array(invCov_final)\n",
    "  cov_final = np.array(cov_final)\n",
    "  y_final = np.expand_dims(y_final,1)\n",
    "  return [x_final, invCov_final, cov_final, y_final], y_final   # with the custom loss the x_train (input) needs to be a list of [inputs, inverseCovariance, labels]\n",
    "  # return [x_final, invCov_final], y_final   # with the custom loss the x_train (input) needs to be a list of [inputs, inverseCovariance, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J7H0PK6Q-NGg",
    "outputId": "6fcb6671-f32c-402a-c1a3-8489231a8d75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--==Types==--\n",
      "--x_train:--\n",
      "\n",
      "  -> input_data: x_train[0]\n",
      "  -> type expected: RaggedTensor\n",
      " <class 'tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor'>\n",
      "\n",
      "  -> invCov: x_train[1]\n",
      "  -> type expected: np.array\n",
      " <class 'numpy.ndarray'>\n",
      "\n",
      "  -> y_train: x_train[2]\n",
      "  -> type expected: np.array\n",
      " <class 'numpy.ndarray'>\n",
      "\n",
      "--y_train:--\n",
      "\n",
      "  -> y_train: y_train\n",
      "  -> type expected: np.array\n",
      " <class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "--==Shapes==--\n",
      "--x_train:--  \n",
      "num of events: 303340\n",
      "\n",
      "  RaggedTensor | Input:  shape = (303340, 16, 18)\n",
      "  np.array     | InvCov: shape = (303340, 25)\n",
      "  np.array     | Labels: shape = (303340, 25)\n",
      "\n",
      "--x_train:--\n",
      "  np.array     | Labels: shape = (303340, 1)\n",
      "x_train : <tf.RaggedTensor [[0.442522257566452, 0.4399665892124176, 0.5602681636810303, 0.10203991085290909, 0.49473685026168823, 1.0, 0.9994895458221436, 0.21632660925388336, 0.007259881589561701, 0.007259881589561701, 0.5519176125526428, 0.0, 0.39372238516807556, 0.0, 0.4237023890018463, 0.0, 0.5532574653625488, 0.0], [0.45607292652130127, 0.4806709289550781, 0.5327455997467041, 0.14891599118709564, 0.5473684072494507, 0.95652174949646, 0.9869040250778198, 0.43687447905540466, 0.004726943094283342, 0.004726943094283342, 0.5563418865203857, 0.0, 0.3950018286705017, 0.0, 0.4254135191440582, 0.0, 0.555824339389801, 0.0], [0.510450005531311, 0.5399274230003357, 0.4743120074272156, 0.09219326078891754, 0.557894766330719, 0.9130434989929199, 0.9742259979248047, 0.43604668974876404, 0.008116372860968113, 0.008116372860968113, 0.5563773512840271, 0.0, 0.3950059711933136, 0.0, 0.4254204034805298, 0.0, 0.5558362007141113, 0.0], [0.5418498516082764, 0.5175445079803467, 0.4687892496585846, 0.01140997838228941, 0.4526315927505493, 0.8260869383811951, 0.9480860829353333, 0.41131314635276794, 0.06716503202915192, 0.06716503202915192, 0.556377649307251, 0.0, 0.395006000995636, 0.0, 0.4254204332828522, 0.0, 0.5558362603187561, 0.0], [0.48893773555755615, 0.45928704738616943, 0.5260181427001953, 0.08510806411504745, 0.4421052634716034, 0.782608687877655, 0.9353087544441223, 0.6138784289360046, 0.008854085579514503, 0.008854085579514503, 0.556377649307251, 0.0, 0.395006000995636, 0.0, 0.4254204332828522, 0.0, 0.5558362603187561, 0.0], [0.4438585638999939, 0.44657742977142334, 0.5564379096031189, 0.0417458713054657, 0.5052631497383118, 0.739130437374115, 0.7677187919616699, 0.29542285203933716, 0.018718363717198372, 0.018718363717198372, 0.556377649307251, 0.0, 0.395006000995636, 0.0, 0.4254204332828522, 0.0, 0.5558362603187561, 0.0], [0.46487507224082947, 0.4893224835395813, 0.5235856771469116, 0.06970063596963882, 0.5473684072494507, 0.695652186870575, 0.7549135088920593, 0.3673320412635803, 0.010969896800816059, 0.010969896800816059, 0.556377649307251, 0.0, 0.395006000995636, 0.0, 0.4254204332828522, 0.0, 0.5558362603187561, 0.0], [0.5550211071968079, 0.551953911781311, 0.4446330964565277, 0.05438368022441864, 0.49473685026168823, 0.6086956262588501, 0.7288685441017151, 0.2223222255706787, 0.01424370426684618, 0.01424370426684618, 0.556377649307251, 0.0, 0.395006000995636, 0.0, 0.4254204332828522, 0.0, 0.5558362603187561, 0.0], [0.533866822719574, 0.5094031691551208, 0.477599561214447, 0.2068084478378296, 0.4526315927505493, 0.5652173757553101, 0.7161188125610352, 0.32825568318367004, 0.0031771287322044373, 0.0031771287322044373, 0.556377649307251, 0.0, 0.395006000995636, 0.0, 0.4254204332828522, 0.0, 0.5558362603187561, 0.0], [0.4828121066093445, 0.45824134349823, 0.5304737091064453, 0.05993078649044037, 0.4526315927505493, 0.52173912525177, 0.7030749917030334, 0.3351324498653412, 0.012867446057498455, 0.012867446057498455, 0.556377649307251, 0.0, 0.395006000995636, 0.0, 0.4254204332828522, 0.0, 0.5558362603187561, 0.0], [0.4503249228000641, 0.4605593979358673, 0.5460062623023987, 0.1343984305858612, 0.5157894492149353, 0.47826087474823, 0.4162885248661041, 0.4404987692832947, 0.0053236884996294975, 0.0053236884996294975, 0.556377649307251, 0.0, 0.395006000995636, 0.0, 0.4254204332828522, 0.0, 0.5558362603187561, 0.0], [0.5148943066596985, 0.5282880663871765, 0.47730281949043274, 0.6603195071220398, 0.5263158082962036, 0.3913043439388275, 0.3903483748435974, 0.0754055604338646, 0.0004273048834875226, 0.0004273048834875226, 0.556377649307251, 0.0, 0.395006000995636, 0.0, 0.4254204332828522, 0.0, 0.5558362603187561, 0.0], [0.5333690643310547, 0.5244799256324768, 0.4702188968658447, 0.06509501487016678, 0.4842105209827423, 0.3478260934352875, 0.3770797848701477, 0.21636953949928284, 0.011794352903962135, 0.011794352903962135, 0.556377649307251, 0.0, 0.395006000995636, 0.0, 0.4254204332828522, 0.0, 0.5558362603187561, 0.0], [0.5226667523384094, 0.4976694583892822, 0.4892614483833313, 0.17610566318035126, 0.4526315927505493, 0.30434781312942505, 0.3641001284122467, 0.5551945567131042, 0.003872755216434598, 0.003872755216434598, 0.556377649307251, 0.0, 0.395006000995636, 0.0, 0.4254204332828522, 0.0, 0.5558362603187561, 0.0], [0.46849074959754944, 0.4766896963119507, 0.5286329984664917, 0.10696706175804138, 0.5157894492149353, 0.21739129722118378, 0.06487853825092316, 0.2103661447763443, 0.006890040822327137, 0.006890040822327137, 0.556377649307251, 0.0, 0.395006000995636, 0.0, 0.4254204332828522, 0.0, 0.5558362603187561, 0.0], [0.4893464148044586, 0.5082195997238159, 0.500893235206604, 0.06838078051805496, 0.5368421077728271, 0.17391304671764374, 0.05135022848844528, 0.39803990721702576, 0.011194948107004166, 0.011194948107004166, 0.556377649307251, 0.0, 0.395006000995636, 0.0, 0.4254204332828522, 0.0, 0.5558362603187561, 0.0]]>\n",
      "y_train : [37.194]\n"
     ]
    }
   ],
   "source": [
    "# split = 450000\n",
    "# split = 3\n",
    "# split = int(unparsed_train.shape[0]-1000)\n",
    "np.random.shuffle(unparsed_train)\n",
    "split = int(unparsed_train.shape[0]*0.75)\n",
    "x_train, y_train = ragged_parser(unparsed_train[:split]) # shuffle data before taking\n",
    "x_test, y_test = ragged_parser(unparsed_train[split:])\n",
    "# x_train, y_train = ragged_parser(unparsed_train[:split])\n",
    "# x_test , y_test  = ragged_parser(unparsed_train[split:split+100])\n",
    "\n",
    "print(\"--==Types==--\")\n",
    "print(\"--x_train:--\")\n",
    "print(\"\\n  -> input_data: x_train[0]\\n  -> type expected: RaggedTensor\\n \"+str(type(x_train[0])))\n",
    "print(\"\\n  -> invCov: x_train[1]\\n  -> type expected: np.array\\n \"+str(type(x_train[1])))\n",
    "print(\"\\n  -> y_train: x_train[2]\\n  -> type expected: np.array\\n \"+str(type(x_train[2])))\n",
    "print(\"\\n--y_train:--\")\n",
    "print(\"\\n  -> y_train: y_train\\n  -> type expected: np.array\\n \"+str(type(y_train)))\n",
    "\n",
    "print(\"\\n\\n--==Shapes==--\")\n",
    "print(\"--x_train:--  \\nnum of events: \" + str(x_train[0].shape[0]))\n",
    "print(\"\\n  RaggedTensor | Input:  shape = \" + \"(\" + str(x_train[0].shape[0]) + \", \"+ str(x_train[0][0].shape[0]) + \", \"+ str(x_train[0][0][0].shape[0]) + \")\")\n",
    "print(\"  np.array     | InvCov: shape = \" + str(x_train[1].shape))\n",
    "print(\"  np.array     | Labels: shape = \" + str(x_train[2].shape))\n",
    "print(\"\\n--x_train:--\")\n",
    "print(\"  np.array     | Labels: shape = \" + str(y_train.shape))\n",
    "\n",
    "print(\"x_train : \" + str(x_train[0][0]))\n",
    "print(\"y_train : \" + str(y_train[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(csv_train[\"cov_11\"],range=[0,0.05],bins=50) # -3 to 3, even distrib\n",
    "plt.title(\"phi\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(3,1,figsize=(5,15))\n",
    "# fig.subplots_adjust(hspace=0.35)\n",
    "\n",
    "# ax[0].hist(np.sqrt(x_train[1][:,24]),range=[0,2],bins=25)\n",
    "# ax[0].set_title(\"cov_44\")\n",
    "\n",
    "# ax[1].hist(np.sqrt(x_train[1][:,24]),range=[0,20],bins=25)\n",
    "# ax[1].set_title(\"cov_44\")\n",
    "\n",
    "# ax[2].hist(np.sqrt(x_train[1][:,24]),range=[0,200],bins=25)\n",
    "# ax[2].set_title(\"cov_44\")\n",
    "# # plt.show()\n",
    "\n",
    "# np.mean(np.sqrt(x_train[1][:,24]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMvnihIl6ail"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdreWH016c08"
   },
   "source": [
    "## Defining Models\n",
    "\n",
    "- model\n",
    "  - Very basic testing RNN model\n",
    "  - Output every timestep\n",
    "\n",
    "- model_timeless\n",
    "  - Very basic testing RNN model\n",
    "  - Output only at the end\n",
    "\n",
    "- RNNTime\n",
    "  - Advanced\n",
    "  - Time distributed, output every timestep\n",
    "\n",
    "- RNNTimeless\n",
    "  - Advanced\n",
    "  - Only output at final layer\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "e8qCwtNw6bFk"
   },
   "outputs": [],
   "source": [
    "def model(x):\n",
    "  x = keras.layers.LSTM(64,activation=\"tanh\", name='input_lstm1', return_sequences=True)(x)\n",
    "  x = keras.layers.TimeDistributed(keras.layers.Dense(32, activation='relu'), name=\"TD1-Dense\")(x)\n",
    "  x = keras.layers.TimeDistributed(keras.layers.Dense(14, activation='linear'), name=\"output-Dense\")(x)\n",
    "  return x\n",
    "def model_timeless(x):\n",
    "  x = keras.layers.LSTM(64,activation=\"tanh\", name='input_lstm1', return_sequences=False)(x)\n",
    "  x = keras.layers.Dense(32, activation='relu', name=\"Dense1\")(x)\n",
    "  x = keras.layers.Dense(5, activation='relu', name=\"output-Dense\")(x)\n",
    "  return x\n",
    "\n",
    "def RNNTime(x):\n",
    "  x = keras.layers.LSTM(128,activation=\"tanh\", name='input_lstm1', stateful=False, return_sequences=True)(x)\n",
    "  x = keras.layers.LSTM(64,activation=\"tanh\", name='lstm2', stateful=False, return_sequences=True)(x)\n",
    "  x = keras.layers.LSTM(32,activation=\"tanh\", name='lstm3', stateful=False, return_sequences=True)(x)\n",
    "  x = keras.layers.TimeDistributed(keras.layers.Dense(32, activation='relu'), name=\"TD1-Dense\")(x)\n",
    "  x = keras.layers.TimeDistributed(keras.layers.Dense(5, activation='linear'), name=\"output-Dense\")(x)\n",
    "  return x\n",
    "\n",
    "def RNNTimeless(x):\n",
    "  x = keras.layers.LSTM(128,activation=\"tanh\", name='input_lstm1', stateful=False, return_sequences=True)(x)\n",
    "  x = keras.layers.Dropout(0.2)(x)\n",
    "  x = keras.layers.LSTM(64,activation=\"tanh\", name='lstm2', stateful=False, return_sequences=True)(x)\n",
    "  x = keras.layers.Dropout(0.2)(x)\n",
    "  x = keras.layers.LSTM(64,activation=\"tanh\", name='lstm3', stateful=False, return_sequences=False)(x)\n",
    "#   x = keras.layers.LSTM(64,activation=\"tanh\", name='lstm3', stateful=False, return_sequences=False)(x)\n",
    "#   x = keras.layers.Dense(32, activation='relu', name=\"Dense1\")(x)\n",
    "  x = keras.layers.Dropout(0.2)(x)\n",
    "  x = keras.layers.Dense(32, activation='relu', name=\"Dense1\")(x)\n",
    "  x = keras.layers.Dropout(0.2)(x)\n",
    "  x = keras.layers.Dense(32, activation='relu', name=\"Dense2\")(x) ## LBR\n",
    "  x = keras.layers.Dropout(0.2)(x)\n",
    "  x = keras.layers.Dense(32, activation='linear', name=\"Dense3\")(x)\n",
    "  x = keras.layers.Dense(1, activation='linear', name=\"output-Dense\")(x)\n",
    "  # x = keras.layers.Dense(5, activation='linear', name=\"output-Dense\")(x)\n",
    "  # x = keras.layers.lambda(# normalize)\n",
    "  return x\n",
    "\n",
    "def RNNTimeless(x):\n",
    "  x = keras.layers.LSTM(256,activation=\"tanh\", name='input_lstm1', stateful=False, dropout=0.2, return_sequences=True)(x)\n",
    "  x = keras.layers.LSTM(256,activation=\"tanh\", name='lstm2', stateful=False, dropout=0.2, return_sequences=True)(x)\n",
    "  x = keras.layers.LSTM(256,activation=\"tanh\", name='lstm3', stateful=False, return_sequences=True)(x)\n",
    "  x = keras.layers.Dropout(0.2)(x)\n",
    "  x = keras.layers.LSTM(128,activation=\"tanh\", name='lstm4', stateful=False, return_sequences=False)(x)\n",
    "#   x = keras.layers.LSTM(64,activation=\"tanh\", name='lstm3', stateful=False, return_sequences=False)(x)\n",
    "#   x = keras.layers.Dense(32, activation='relu', name=\"Dense1\")(x)\n",
    "  x = keras.layers.Dropout(0.2)(x)\n",
    "  x = keras.layers.Dense(128, activation='linear', name=\"Dense1\")(x)\n",
    "  x = keras.layers.Dropout(0.2)(x)\n",
    "  x = keras.layers.Dense(128, activation='linear', name=\"Dense2\")(x) ## LBR\n",
    "  x = keras.layers.Dropout(0.2)(x)\n",
    "  x = keras.layers.Dense(32, activation='linear', name=\"Dense3\")(x)\n",
    "  x = keras.layers.Dense(1, activation='linear', name=\"output-Dense\")(x)\n",
    "  # x = keras.layers.Dense(5, activation='linear', name=\"output-Dense\")(x)\n",
    "  # x = keras.layers.lambda(# normalize)\n",
    "  return x\n",
    "\n",
    "\n",
    "# def RNNTimeless(x):\n",
    "#   x = keras.layers.LSTM(128,activation=\"tanh\", name='input_lstm1', stateful=False, return_sequences=True)(x)\n",
    "#   x = keras.layers.LSTM(64,activation=\"tanh\", name='lstm2', stateful=False, return_sequences=True)(x)\n",
    "#   x = keras.layers.LSTM(64,activation=\"tanh\", name='lstm3', stateful=False, return_sequences=False)(x)\n",
    "#   x = keras.layers.Dense(32, activation='relu', name=\"Dense1\")(x)\n",
    "#   x = keras.layers.Dense(5, activation='linear', name=\"output-Dense\")(x)\n",
    "#   # x = keras.layers.lambda(# normalize)\n",
    "#   return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gtf37tFTB5HU"
   },
   "source": [
    "## Custom Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOZIj6R8u0VG"
   },
   "source": [
    "### V1 Originial, unedited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "v8iA9da3HLBs"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "#--------------------------------------------\n",
    "# Define custom loss function \n",
    "def customLoss(y_true, y_pred, invcov):\n",
    "  # print(type(y_true))    #<class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>\n",
    "\n",
    "  batch_size = tf.shape(y_pred)[0]\n",
    "  print('y_pred shape: ' + str(y_pred.shape) )  # y_pred shape is (batch, 5)\n",
    "  print('y_true shape: ' + str(y_true.shape) )  # y_true shape is (batch, 5)\n",
    "  print('invcov shape: ' + str(invcov.shape) )  # invcov shape is (batch, 25)\n",
    "  \n",
    "  y_pred = K.reshape(y_pred, (batch_size, 5,1)) # y_pred  shape is now (batch, 5,1)\n",
    "  y_true = K.reshape(y_true, (batch_size, 5,1)) # y_state shape is now (batch, 5,1)\n",
    "  invcov = K.reshape(invcov, (batch_size, 5,5)) # invcov  shape is now (batch, 5,5)\n",
    "  \n",
    "  # n.b. we must use tf.transpose here an not K.transpose since the latter does not allow perm argument\n",
    "  invcov = tf.transpose(invcov, perm=[0,2,1])     # invcov shape is now (batch, 5,5)\n",
    "  \n",
    "  # Difference between prediction and true state vectors\n",
    "  y_diff = y_pred - y_true\n",
    "\n",
    "  # n.b. use \"batch_dot\" and not \"dot\"!\n",
    "  y_dot = K.batch_dot(invcov, y_diff)           # y_dot shape is (batch,5,1)\n",
    "  y_dot = K.reshape(y_dot, (batch_size, 1, 5))  # y_dot shape is now (batch,1,5)\n",
    "  y_loss = K.batch_dot(y_dot, y_diff)           # y_loss shape is (batch,1,1)\n",
    "  y_loss = K.reshape(y_loss, (batch_size,))     # y_loss shape is now (batch)\n",
    "  return y_loss\n",
    "\n",
    "#--------------------------------------------\n",
    "# Test loss function\n",
    "# x_test = x_train[2][0]\n",
    "# y_test = model.predict([x_train[0][0:1],x_train[1][0:1],x_train[2][0:1]])\n",
    "# y_test = np.squeeze(y_test)\n",
    "# inconv_test = x_train[1][0]\n",
    "\n",
    "# loss = K.eval(customLoss(K.variable([x_test,x_test,x_test]), K.variable([y_test,y_test,y_test]), K.variable([inconv_test,inconv_test,inconv_test])))\n",
    "# print('loss shape: '    + str(loss.shape)    )\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXxfMKTqTvBC"
   },
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ZX3nAlhgTu4h"
   },
   "outputs": [],
   "source": [
    "def customMetric(y_true, y_pred, cov, id=0):\n",
    "  batch_size = tf.shape(y_pred)[0]\n",
    "\n",
    "  y_pred = K.reshape(y_pred, (batch_size, 5,1)) # y_pred  shape is now (batch, 5,1)\n",
    "  y_true = K.reshape(y_true, (batch_size, 5,1)) # y_state shape is now (batch, 5,1)\n",
    "  cov = K.reshape(cov, (batch_size, 5,5)) # cov  shape is now (batch, 5,5)\n",
    "  # cov = tf.transpose(cov, perm=[0,2,1])     # cov shape is now (batch, 5,5)\n",
    "  y_diff = y_pred[:,id] - y_true[:,id]\n",
    "  # y_diff = K.reshape(y_diff, (batch_size,1))\n",
    "  cov = K.reshape(cov[:,id,id], (batch_size,1))\n",
    "  # print(\"diff:\\n\",y_diff)\n",
    "  print(\"cov:\\n\",cov)\n",
    "  # return (y_diff*y_diff)/(cov[:,id,id])\n",
    "  return tf.math.square(y_diff)/(cov)\n",
    "\n",
    "# ccov = x_train[2][0:6]\n",
    "# ccov = np.reshape(ccov, (6,5,5))\n",
    "\n",
    "# print(ccov)\n",
    "\n",
    "# metric = K.eval(customMetric(y_train[0:6],y_train[1:7],x_train[2][0:6],0))\n",
    "# print(\"metric: \\n\",metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[   622.012     19.605    -98.929    -46.267    104.764]\n",
      "  [    19.605      0.704     -1.88      -1.573      8.643]\n",
      "  [   -98.929     -1.88      39.768      5.971     63.607]\n",
      "  [   -46.267     -1.573      5.971      3.742    -14.542]\n",
      "  [   104.764      8.643     63.607    -14.542    576.643]]\n",
      "\n",
      " [[395977.781   -241.81  -35112.598   -566.26  -40120.605]\n",
      "  [  -241.81       7.11      31.778     -0.638    864.074]\n",
      "  [-35112.598     31.778   3138.282     49.355   4798.816]\n",
      "  [  -566.26      -0.638     49.355      1.234    -61.209]\n",
      "  [-40120.605    864.074   4798.816    -61.209 105514.469]]\n",
      "\n",
      " [[     0.019      0.005      0.002      0.008     -0.022]\n",
      "  [     0.005      0.001      0.001      0.002     -0.005]\n",
      "  [     0.002      0.001      0.         0.002     -0.003]\n",
      "  [     0.008      0.002      0.002      0.008     -0.006]\n",
      "  [    -0.022     -0.005     -0.003     -0.006      0.052]]\n",
      "\n",
      " [[     0.018      0.001     -0.009     -0.007     -0.014]\n",
      "  [     0.001      0.         0.        -0.001      0.   ]\n",
      "  [    -0.009      0.         0.031     -0.001      0.077]\n",
      "  [    -0.007     -0.001     -0.001      0.005     -0.008]\n",
      "  [    -0.014      0.         0.077     -0.008      0.386]]\n",
      "\n",
      " [[    34.232      0.132    -18.262     -0.449     -9.034]\n",
      "  [     0.132      0.016     -0.        -0.014      0.079]\n",
      "  [   -18.262     -0.        11.373      0.122      7.383]\n",
      "  [    -0.449     -0.014      0.122      0.034      0.009]\n",
      "  [    -9.034      0.079      7.383      0.009     20.   ]]\n",
      "\n",
      " [[  6462.82       2.702   -539.861   -210.963 -16684.939]\n",
      "  [     2.702      1.358     -0.226     -1.06    -282.857]\n",
      "  [  -539.861     -0.226     45.124     17.66    1394.616]\n",
      "  [  -210.963     -1.06      17.66       9.726    735.459]\n",
      "  [-16684.939   -282.857   1394.616    735.459  99276.656]]]\n",
      "pred:\n",
      " tf.Tensor(\n",
      "[[30.878]\n",
      " [ 3.87 ]\n",
      " [13.867]\n",
      " [30.616]\n",
      " [ 5.859]\n",
      " [16.527]], shape=(6, 1), dtype=float64)\n",
      "cov:\n",
      " tf.Tensor(\n",
      "[[3.742]\n",
      " [1.234]\n",
      " [0.008]\n",
      " [0.005]\n",
      " [0.034]\n",
      " [9.726]], shape=(6, 1), dtype=float64)\n",
      "diff:\n",
      " tf.Tensor(\n",
      "[[ -6.316]\n",
      " [-27.008]\n",
      " [  9.997]\n",
      " [ 16.749]\n",
      " [-24.757]\n",
      " [ 10.668]], shape=(6, 1), dtype=float64)\n",
      "metric: \n",
      " [[   10.662]\n",
      " [  591.078]\n",
      " [13047.481]\n",
      " [56628.597]\n",
      " [18046.247]\n",
      " [   11.701]]\n"
     ]
    }
   ],
   "source": [
    "def customMetric(y_true, y_pred, cov, id=0):\n",
    "  batch_size = tf.shape(y_pred)[0]\n",
    "\n",
    "  y_pred = K.reshape(y_pred, (batch_size, 1)) # y_pred  shape is now (batch, 5,1)\n",
    "  y_true = K.reshape(y_true, (batch_size, 1)) # y_state shape is now (batch, 5,1)\n",
    "  cov = K.reshape(cov, (batch_size, 5,5)) # cov  shape is now (batch, 5,5)\n",
    "  # cov = tf.transpose(cov, perm=[0,2,1])     # cov shape is now (batch, 5,5)\n",
    "  print(\"pred:\\n\",y_pred)\n",
    "  y_diff = y_pred - y_true\n",
    "  # y_diff = K.reshape(y_diff, (batch_size,1))\n",
    "  cov = K.reshape(cov[:,id,id], (batch_size,1))\n",
    "  # print(\"diff:\\n\",y_diff)\n",
    "  print(\"cov:\\n\",cov)\n",
    "  print(\"diff:\\n\",y_diff)\n",
    "  # return (y_diff*y_diff)/(cov[:,id,id])\n",
    "  return tf.math.square(y_diff)/(cov)\n",
    "\n",
    "ccov = x_train[2][0:6]\n",
    "ccov = np.reshape(ccov, (6,5,5))\n",
    "\n",
    "print(ccov)\n",
    "\n",
    "metric = K.eval(customMetric(np.expand_dims(y_train[0:6,0],1),np.expand_dims(y_train[1:7,0],1),x_train[2][0:6],3))\n",
    "print(\"metric: \\n\",metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qw41A73h-zGB"
   },
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SZ7d8PMx652m",
    "outputId": "aab903f4-7785-4519-ef41-4067f641d5e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:\n",
      " Tensor(\"Reshape:0\", shape=(None, 1), dtype=float32)\n",
      "cov:\n",
      " Tensor(\"Reshape_3:0\", shape=(None, 1), dtype=float32)\n",
      "diff:\n",
      " Tensor(\"Sub:0\", shape=(None, 1), dtype=float32)\n",
      "Model: \"RNNModel\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 18)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_lstm1 (LSTM)              (None, None, 256)    281600      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm2 (LSTM)                    (None, None, 256)    525312      input_lstm1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm3 (LSTM)                    (None, None, 256)    525312      lstm2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, 256)    0           lstm3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lstm4 (LSTM)                    (None, 128)          197120      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           lstm4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dense1 (Dense)                  (None, 128)          16512       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           Dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Dense2 (Dense)                  (None, 128)          16512       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           Dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Dense3 (Dense)                  (None, 32)           4128        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "output-Dense (Dense)            (None, 1)            33          Dense3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           output-Dense[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape/shape (Tens [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1/shape (Te [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2/shape (Te [(3,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 1)]          0           output-Dense[0][0]               \n",
      "                                                                 tf_op_layer_Reshape/shape[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, 1)]          0           input_2[0][0]                    \n",
      "                                                                 tf_op_layer_Reshape_1/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2 (TensorFl [(None, 5, 5)]       0           input_4[0][0]                    \n",
      "                                                                 tf_op_layer_Reshape_2/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub (TensorFlowOpLa [(None, 1)]          0           tf_op_layer_Reshape[0][0]        \n",
      "                                                                 tf_op_layer_Reshape_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(None,)]            0           tf_op_layer_Reshape_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3/shape (Te [(2,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Square (TensorFlowO [(None, 1)]          0           tf_op_layer_Sub[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3 (TensorFl [(None, 1)]          0           tf_op_layer_strided_slice_1[0][0]\n",
      "                                                                 tf_op_layer_Reshape_3/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_RealDiv (TensorFlow [(None, 1)]          0           tf_op_layer_Square[0][0]         \n",
      "                                                                 tf_op_layer_Reshape_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_metric (AddMetric)          (None, 1)            0           tf_op_layer_RealDiv[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 1,566,529\n",
      "Trainable params: 1,566,529\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# --==Not in use?==--\n",
    "# lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=1e-3,\n",
    "#     decay_steps=10000,\n",
    "#     decay_rate=0.8)\n",
    "from keras.layers import Dense\n",
    "\n",
    "# nInput = 10\n",
    "nInput = 18\n",
    "\n",
    "# --==Set seed to get identical results==-- begin\n",
    "# from tensorflow.random import set_seed\n",
    "# np.random.seed(1)\n",
    "# set_seed(2)\n",
    "# --==Set seed to get identical results==-- end\n",
    "\n",
    "#--==Set Weights==--\n",
    "# loss_weights = [1/(sd**2)]\n",
    "# loss_weights = np.array(loss_weights)/sum(loss_weights)\n",
    "# model.compile(optimizer=optimizer, loss=\"mse\", loss_weights=loss_weights, metrics=[\"mae\"])\n",
    "\n",
    "inputs = keras.Input((None,nInput))\n",
    "# input_true = keras.Input((5,))\n",
    "input_true = keras.Input((1,))\n",
    "input_incov = keras.Input((25,))\n",
    "input_cov_f = keras.Input((25,))\n",
    "all_inputs = [inputs, input_incov, input_cov_f, input_true]\n",
    "# all_inputs = [inputs, input_incov, input_true]\n",
    "\n",
    "# --==Choose model==--\n",
    "# x = model(inputs)\n",
    "# x = model_timeless(inputs)\n",
    "# x = RNNTime(inputs)\n",
    "x = RNNTimeless(inputs)\n",
    "# x = RNNTimeStateful(inputs)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# outs = {\n",
    "#     \"q_pt\":Dense(1, name=\"q_pt\")(x),\n",
    "#     \"phi\":Dense(1, name=\"phi\")(x),\n",
    "#     \"tanl\":Dense(1, name=\"tanl\")(x),\n",
    "#     \"D\":Dense(1, name=\"D\")(x),\n",
    "#     \"z\":Dense(1, name=\"z\")(x)\n",
    "# }\n",
    "\n",
    "# y_dict = {\n",
    "#     \"q_pt\":y_train[:,0],\n",
    "#     \"phi\":y_train[:,1],\n",
    "#     \"tanl\":y_train[:,2],\n",
    "#     \"D\":y_train[:,3],\n",
    "#     \"z\":y_train[:,4]\n",
    "# }\n",
    "\n",
    "# model = keras.Model(inputs=all_inputs, outputs=outs, name=\"RNNModel\")\n",
    "\n",
    "model = keras.Model(inputs=all_inputs, outputs=x, name=\"RNNModel\")\n",
    "\n",
    "# model.add_metric(customMetric(input_true, x, input_cov_f, 0),name=\"q_pt\")\n",
    "# model.add_metric(customMetric(input_true, x, input_cov_f, 1),name=\"phi\")\n",
    "# model.add_metric(customMetric(input_true, x, input_cov_f, 2),name=\"tanl\")\n",
    "# model.add_metric(customMetric(input_true, x, input_cov_f, 3),name=\"D\")\n",
    "# model.add_metric(customMetric(input_true, x, input_cov_f, 4),name=\"z\")\n",
    "\n",
    "# model.add_loss(customLoss(input_true, x, input_incov))\n",
    "# model.compile(loss=None, optimizer=optimizer, metrics=[\"mae\"])\n",
    "\n",
    "# model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.add_metric(customMetric(input_true, x, input_cov_f, glob_index),name=\"customMetric\")\n",
    "# try as loss\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"mae\"])\n",
    "# model.compile(loss=\"\", optimizer=optimizer, metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkjx1-6Gr76F"
   },
   "source": [
    "### Custom Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "t2pxxUfH7sjY"
   },
   "outputs": [],
   "source": [
    "def concat_hist(H1,H2):\n",
    "  H = {}\n",
    "  for i in H1.keys():\n",
    "    H[i] = list(np.append(np.array(H1[i]),np.array(H2[i])))\n",
    "  return H\n",
    "H = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sjLh8Eh07HRW",
    "outputId": "e8312305-0acd-4240-c575-5b48161d1655"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 36s 240ms/step - loss: 337.7484 - mae: 9.9549 - customMetric: 130518.7109 - val_loss: 276.9244 - val_mae: 9.7420 - val_customMetric: 223835.2500\n",
      "Epoch 2/100\n",
      "149/149 [==============================] - 34s 229ms/step - loss: 323.7560 - mae: 9.4851 - customMetric: 138228.6875 - val_loss: 266.9675 - val_mae: 9.6340 - val_customMetric: 381260.0625\n",
      "Epoch 3/100\n",
      "149/149 [==============================] - 34s 229ms/step - loss: 312.5817 - mae: 9.1187 - customMetric: 159387.3594 - val_loss: 267.4952 - val_mae: 10.2035 - val_customMetric: 440279.1562\n",
      "Epoch 4/100\n",
      "149/149 [==============================] - 34s 225ms/step - loss: 278.7581 - mae: 7.7106 - customMetric: 117319.0078 - val_loss: 208.0556 - val_mae: 7.0225 - val_customMetric: 429192.7500\n",
      "Epoch 5/100\n",
      "149/149 [==============================] - 34s 230ms/step - loss: 265.6203 - mae: 7.1453 - customMetric: 90428.4688 - val_loss: 253.0674 - val_mae: 9.9077 - val_customMetric: 657290.5000\n",
      "Epoch 6/100\n",
      "149/149 [==============================] - 34s 227ms/step - loss: 263.0936 - mae: 7.0436 - customMetric: 83393.2891 - val_loss: 236.8159 - val_mae: 9.2412 - val_customMetric: 599318.8750\n",
      "Epoch 7/100\n",
      "149/149 [==============================] - 33s 224ms/step - loss: 260.0571 - mae: 6.8819 - customMetric: 92945.2969 - val_loss: 225.4827 - val_mae: 8.1000 - val_customMetric: 600563.1875\n",
      "Epoch 8/100\n",
      "149/149 [==============================] - 33s 223ms/step - loss: 256.6601 - mae: 6.7362 - customMetric: 95635.3438 - val_loss: 232.4965 - val_mae: 8.9190 - val_customMetric: 611027.8125\n",
      "Epoch 9/100\n",
      "149/149 [==============================] - 34s 227ms/step - loss: 250.9806 - mae: 6.4683 - customMetric: 102628.8594 - val_loss: 251.2290 - val_mae: 10.0607 - val_customMetric: 613470.3750\n",
      "Epoch 10/100\n",
      "149/149 [==============================] - 34s 230ms/step - loss: 244.5861 - mae: 6.1754 - customMetric: 75518.2422 - val_loss: 220.7978 - val_mae: 8.3422 - val_customMetric: 481187.7188\n",
      "Epoch 11/100\n",
      "149/149 [==============================] - 34s 227ms/step - loss: 240.0140 - mae: 5.9572 - customMetric: 108397.5234 - val_loss: 330.8104 - val_mae: 13.0522 - val_customMetric: 799222.5625\n",
      "Epoch 12/100\n",
      "149/149 [==============================] - 33s 223ms/step - loss: 237.0304 - mae: 5.7844 - customMetric: 103564.2969 - val_loss: 281.7942 - val_mae: 11.2546 - val_customMetric: 709548.3750\n",
      "Epoch 13/100\n",
      "149/149 [==============================] - 34s 225ms/step - loss: 233.9357 - mae: 5.6294 - customMetric: 87692.5156 - val_loss: 315.9123 - val_mae: 12.6459 - val_customMetric: 630912.2500\n",
      "Epoch 14/100\n",
      "149/149 [==============================] - 34s 227ms/step - loss: 231.9642 - mae: 5.5486 - customMetric: 90079.9922 - val_loss: 266.5421 - val_mae: 11.0806 - val_customMetric: 488475.1562\n",
      "Epoch 15/100\n",
      "149/149 [==============================] - 34s 230ms/step - loss: 229.5697 - mae: 5.4166 - customMetric: 93875.0625 - val_loss: 271.6259 - val_mae: 10.8681 - val_customMetric: 553651.8125\n",
      "Epoch 16/100\n",
      "149/149 [==============================] - 34s 230ms/step - loss: 227.7478 - mae: 5.3372 - customMetric: 77210.5312 - val_loss: 238.9379 - val_mae: 9.7848 - val_customMetric: 333864.5625\n",
      "Epoch 17/100\n",
      "149/149 [==============================] - 34s 231ms/step - loss: 227.1298 - mae: 5.3292 - customMetric: 93267.7031 - val_loss: 286.1582 - val_mae: 11.8205 - val_customMetric: 475951.9375\n",
      "Epoch 18/100\n",
      "149/149 [==============================] - 34s 226ms/step - loss: 227.3217 - mae: 5.3476 - customMetric: 81940.1016 - val_loss: 205.5647 - val_mae: 7.7964 - val_customMetric: 299069.5000\n",
      "Epoch 19/100\n",
      "149/149 [==============================] - 34s 228ms/step - loss: 225.5800 - mae: 5.2476 - customMetric: 109828.8672 - val_loss: 217.6636 - val_mae: 8.6150 - val_customMetric: 391298.8750\n",
      "Epoch 20/100\n",
      "149/149 [==============================] - 34s 228ms/step - loss: 225.8666 - mae: 5.2518 - customMetric: 97723.5234 - val_loss: 214.7085 - val_mae: 8.2268 - val_customMetric: 226651.7656\n",
      "Epoch 21/100\n",
      "149/149 [==============================] - 34s 226ms/step - loss: 224.3249 - mae: 5.1676 - customMetric: 90075.0859 - val_loss: 215.9473 - val_mae: 7.2562 - val_customMetric: 170175.6562\n",
      "Epoch 22/100\n",
      "149/149 [==============================] - 34s 231ms/step - loss: 224.4500 - mae: 5.1735 - customMetric: 82987.4531 - val_loss: 240.1173 - val_mae: 7.3405 - val_customMetric: 137904.1406\n",
      "Epoch 23/100\n",
      "149/149 [==============================] - 34s 227ms/step - loss: 223.9617 - mae: 5.1680 - customMetric: 107723.6328 - val_loss: 206.1441 - val_mae: 7.2766 - val_customMetric: 209485.2344\n",
      "Epoch 24/100\n",
      "149/149 [==============================] - 34s 230ms/step - loss: 223.4562 - mae: 5.1360 - customMetric: 86699.0625 - val_loss: 250.2415 - val_mae: 7.6237 - val_customMetric: 126631.7578\n",
      "Epoch 25/100\n",
      "149/149 [==============================] - 33s 223ms/step - loss: 222.1707 - mae: 5.0908 - customMetric: 101893.6953 - val_loss: 251.5092 - val_mae: 7.4263 - val_customMetric: 127562.7656\n",
      "Epoch 26/100\n",
      "149/149 [==============================] - 33s 225ms/step - loss: 223.1086 - mae: 5.1305 - customMetric: 84914.9062 - val_loss: 227.3015 - val_mae: 7.2888 - val_customMetric: 135175.6250\n",
      "Epoch 27/100\n",
      "149/149 [==============================] - 34s 229ms/step - loss: 222.1094 - mae: 5.0699 - customMetric: 94093.4609 - val_loss: 258.3760 - val_mae: 7.5461 - val_customMetric: 107125.7578\n",
      "Epoch 28/100\n",
      "149/149 [==============================] - 33s 224ms/step - loss: 221.2086 - mae: 5.0258 - customMetric: 95929.4375 - val_loss: 214.8490 - val_mae: 6.7052 - val_customMetric: 182982.5938\n",
      "Epoch 29/100\n",
      "149/149 [==============================] - 34s 230ms/step - loss: 221.0297 - mae: 5.0433 - customMetric: 85376.8984 - val_loss: 235.9897 - val_mae: 7.4513 - val_customMetric: 151701.4375\n",
      "Epoch 30/100\n",
      "149/149 [==============================] - 34s 229ms/step - loss: 221.8454 - mae: 5.0619 - customMetric: 95824.5156 - val_loss: 220.3987 - val_mae: 7.0419 - val_customMetric: 169333.7500\n",
      "Epoch 31/100\n",
      "149/149 [==============================] - 34s 228ms/step - loss: 220.9827 - mae: 5.0021 - customMetric: 128051.3281 - val_loss: 234.3219 - val_mae: 7.1151 - val_customMetric: 136568.9688\n",
      "Epoch 32/100\n",
      "149/149 [==============================] - 33s 224ms/step - loss: 220.2468 - mae: 4.9755 - customMetric: 94266.8359 - val_loss: 244.8192 - val_mae: 7.5556 - val_customMetric: 133425.5156\n",
      "Epoch 33/100\n",
      "149/149 [==============================] - 34s 228ms/step - loss: 220.4960 - mae: 5.0168 - customMetric: 105425.5078 - val_loss: 202.5734 - val_mae: 7.4713 - val_customMetric: 257940.8594\n",
      "Epoch 34/100\n",
      "149/149 [==============================] - 32s 218ms/step - loss: 220.4794 - mae: 5.0247 - customMetric: 74032.4297 - val_loss: 200.0946 - val_mae: 7.1043 - val_customMetric: 244906.9844\n",
      "Epoch 35/100\n",
      "149/149 [==============================] - 34s 226ms/step - loss: 219.3543 - mae: 4.9459 - customMetric: 89298.8984 - val_loss: 228.3410 - val_mae: 7.2958 - val_customMetric: 168747.2812\n",
      "Epoch 36/100\n",
      "149/149 [==============================] - 34s 228ms/step - loss: 219.5392 - mae: 4.9595 - customMetric: 88107.8438 - val_loss: 231.4376 - val_mae: 7.1737 - val_customMetric: 130778.0625\n",
      "Epoch 37/100\n",
      "149/149 [==============================] - 34s 227ms/step - loss: 218.8051 - mae: 4.9157 - customMetric: 92595.3594 - val_loss: 230.0051 - val_mae: 7.9534 - val_customMetric: 171395.6562\n",
      "Epoch 38/100\n",
      "149/149 [==============================] - 33s 222ms/step - loss: 219.4669 - mae: 4.9522 - customMetric: 113076.5078 - val_loss: 254.5716 - val_mae: 7.5960 - val_customMetric: 108815.5391\n",
      "Epoch 39/100\n",
      "149/149 [==============================] - 33s 225ms/step - loss: 219.4308 - mae: 4.9643 - customMetric: 90260.3984 - val_loss: 228.4429 - val_mae: 7.8737 - val_customMetric: 194214.8281\n",
      "Epoch 40/100\n",
      "149/149 [==============================] - 34s 226ms/step - loss: 218.4945 - mae: 4.9115 - customMetric: 91748.6250 - val_loss: 223.9553 - val_mae: 7.7133 - val_customMetric: 171924.5781\n",
      "Epoch 41/100\n",
      "149/149 [==============================] - 33s 224ms/step - loss: 220.2800 - mae: 5.0093 - customMetric: 95735.0859 - val_loss: 206.2730 - val_mae: 6.7761 - val_customMetric: 188148.0312\n",
      "Epoch 42/100\n",
      "149/149 [==============================] - 34s 229ms/step - loss: 217.8112 - mae: 4.9050 - customMetric: 116832.7500 - val_loss: 236.4449 - val_mae: 7.4047 - val_customMetric: 161764.3906\n",
      "Epoch 43/100\n",
      "149/149 [==============================] - 33s 222ms/step - loss: 218.9107 - mae: 4.9194 - customMetric: 84571.6484 - val_loss: 200.8343 - val_mae: 6.8524 - val_customMetric: 185335.5938\n",
      "Epoch 44/100\n",
      "149/149 [==============================] - 33s 218ms/step - loss: 217.2482 - mae: 4.8513 - customMetric: 88209.9375 - val_loss: 223.7278 - val_mae: 7.5060 - val_customMetric: 162278.0781\n",
      "Epoch 45/100\n",
      "149/149 [==============================] - 33s 222ms/step - loss: 216.8454 - mae: 4.8729 - customMetric: 97874.6016 - val_loss: 250.1955 - val_mae: 7.1310 - val_customMetric: 90541.4062\n",
      "Epoch 46/100\n",
      "149/149 [==============================] - 32s 216ms/step - loss: 217.6793 - mae: 4.9131 - customMetric: 94226.4531 - val_loss: 247.4816 - val_mae: 8.1698 - val_customMetric: 144035.3594\n",
      "Epoch 47/100\n",
      "149/149 [==============================] - 33s 223ms/step - loss: 217.3617 - mae: 4.8538 - customMetric: 122837.2109 - val_loss: 238.1117 - val_mae: 7.4616 - val_customMetric: 136439.8906\n",
      "Epoch 48/100\n",
      "149/149 [==============================] - 34s 228ms/step - loss: 216.7646 - mae: 4.8644 - customMetric: 91030.1406 - val_loss: 245.3967 - val_mae: 7.5564 - val_customMetric: 131795.7656\n",
      "Epoch 49/100\n",
      "149/149 [==============================] - 34s 225ms/step - loss: 216.7639 - mae: 4.8050 - customMetric: 107630.9375 - val_loss: 243.3097 - val_mae: 7.2703 - val_customMetric: 108295.4453\n",
      "Epoch 50/100\n",
      "149/149 [==============================] - 34s 226ms/step - loss: 216.3218 - mae: 4.8540 - customMetric: 88293.2656 - val_loss: 226.1987 - val_mae: 8.3985 - val_customMetric: 238547.8281\n",
      "Epoch 51/100\n",
      "149/149 [==============================] - 34s 226ms/step - loss: 216.1043 - mae: 4.8143 - customMetric: 89091.4219 - val_loss: 224.5827 - val_mae: 7.2818 - val_customMetric: 199562.4062\n",
      "Epoch 52/100\n",
      "149/149 [==============================] - 34s 225ms/step - loss: 216.2155 - mae: 4.8685 - customMetric: 94602.1562 - val_loss: 245.5864 - val_mae: 7.5319 - val_customMetric: 129690.1641\n",
      "Epoch 53/100\n",
      "149/149 [==============================] - 34s 227ms/step - loss: 217.3659 - mae: 4.8667 - customMetric: 96422.7891 - val_loss: 219.1593 - val_mae: 8.0213 - val_customMetric: 202486.5625\n",
      "Epoch 54/100\n",
      "149/149 [==============================] - 33s 222ms/step - loss: 215.7660 - mae: 4.7871 - customMetric: 110691.1562 - val_loss: 233.0101 - val_mae: 8.0445 - val_customMetric: 160602.7969\n",
      "Epoch 55/100\n",
      "149/149 [==============================] - 33s 219ms/step - loss: 216.7772 - mae: 4.8570 - customMetric: 90006.6562 - val_loss: 218.2191 - val_mae: 8.5758 - val_customMetric: 302135.0312\n",
      "Epoch 56/100\n",
      "149/149 [==============================] - 32s 216ms/step - loss: 216.4330 - mae: 4.8542 - customMetric: 84047.7734 - val_loss: 216.0043 - val_mae: 7.4951 - val_customMetric: 241328.4531\n",
      "Epoch 57/100\n",
      "149/149 [==============================] - 33s 219ms/step - loss: 215.4326 - mae: 4.7850 - customMetric: 104107.9453 - val_loss: 211.7230 - val_mae: 7.7933 - val_customMetric: 270335.1250\n",
      "Epoch 58/100\n",
      "149/149 [==============================] - 33s 220ms/step - loss: 214.7400 - mae: 4.7839 - customMetric: 106575.5703 - val_loss: 191.1117 - val_mae: 6.6295 - val_customMetric: 241809.8281\n",
      "Epoch 59/100\n",
      "149/149 [==============================] - 33s 222ms/step - loss: 213.7593 - mae: 4.7889 - customMetric: 95144.1719 - val_loss: 202.8438 - val_mae: 7.8209 - val_customMetric: 346324.7500\n",
      "Epoch 60/100\n",
      "149/149 [==============================] - 32s 217ms/step - loss: 216.3507 - mae: 4.8364 - customMetric: 119086.7656 - val_loss: 209.3044 - val_mae: 7.7602 - val_customMetric: 292145.5625\n",
      "Epoch 61/100\n",
      "149/149 [==============================] - 33s 221ms/step - loss: 214.9599 - mae: 4.8704 - customMetric: 91367.1797 - val_loss: 206.6578 - val_mae: 7.5439 - val_customMetric: 278636.1250\n",
      "Epoch 62/100\n",
      "149/149 [==============================] - 33s 219ms/step - loss: 214.4337 - mae: 4.8167 - customMetric: 129991.7891 - val_loss: 218.8268 - val_mae: 7.4792 - val_customMetric: 210446.9844\n",
      "Epoch 63/100\n",
      "149/149 [==============================] - 33s 220ms/step - loss: 215.9566 - mae: 4.8920 - customMetric: 99135.1172 - val_loss: 207.4861 - val_mae: 7.6961 - val_customMetric: 252742.2344\n",
      "Epoch 64/100\n",
      "149/149 [==============================] - 33s 221ms/step - loss: 214.5250 - mae: 4.8054 - customMetric: 85517.6484 - val_loss: 216.3246 - val_mae: 8.2869 - val_customMetric: 285525.0625\n",
      "Epoch 65/100\n",
      "149/149 [==============================] - 33s 221ms/step - loss: 212.5225 - mae: 4.7564 - customMetric: 83480.1875 - val_loss: 207.3183 - val_mae: 7.8767 - val_customMetric: 318109.2812\n",
      "Epoch 66/100\n",
      "149/149 [==============================] - 34s 226ms/step - loss: 214.6090 - mae: 4.8691 - customMetric: 80362.4297 - val_loss: 232.1904 - val_mae: 9.6164 - val_customMetric: 388157.3438\n",
      "Epoch 67/100\n",
      "149/149 [==============================] - 34s 225ms/step - loss: 216.0318 - mae: 4.9054 - customMetric: 101258.0000 - val_loss: 209.9478 - val_mae: 8.1730 - val_customMetric: 343418.0312\n",
      "Epoch 68/100\n",
      "149/149 [==============================] - 34s 228ms/step - loss: 211.5045 - mae: 4.6633 - customMetric: 92305.0078 - val_loss: 204.1958 - val_mae: 7.6241 - val_customMetric: 270329.7500\n",
      "Epoch 69/100\n",
      "149/149 [==============================] - 34s 225ms/step - loss: 212.0279 - mae: 4.8131 - customMetric: 114764.1719 - val_loss: 207.2880 - val_mae: 7.7578 - val_customMetric: 281018.0000\n",
      "Epoch 70/100\n",
      "149/149 [==============================] - 34s 229ms/step - loss: 214.0723 - mae: 4.8331 - customMetric: 77506.7031 - val_loss: 211.1136 - val_mae: 7.5400 - val_customMetric: 218488.3125\n",
      "Epoch 71/100\n",
      "149/149 [==============================] - 34s 226ms/step - loss: 212.7713 - mae: 4.8081 - customMetric: 93964.4453 - val_loss: 210.1437 - val_mae: 7.5168 - val_customMetric: 273407.3750\n",
      "Epoch 72/100\n",
      "149/149 [==============================] - 34s 226ms/step - loss: 213.8916 - mae: 4.8327 - customMetric: 98475.0469 - val_loss: 212.0130 - val_mae: 6.8925 - val_customMetric: 223130.7812\n",
      "Epoch 73/100\n",
      "149/149 [==============================] - 34s 227ms/step - loss: 210.6413 - mae: 4.7287 - customMetric: 84134.6641 - val_loss: 260.0678 - val_mae: 9.9184 - val_customMetric: 435796.0938\n",
      "Epoch 74/100\n",
      "149/149 [==============================] - 34s 226ms/step - loss: 218.6121 - mae: 5.0258 - customMetric: 124275.4375 - val_loss: 201.0119 - val_mae: 7.4995 - val_customMetric: 228849.6094\n",
      "Epoch 75/100\n",
      "149/149 [==============================] - 33s 224ms/step - loss: 209.4232 - mae: 4.7955 - customMetric: 102403.8828 - val_loss: 220.6066 - val_mae: 7.3200 - val_customMetric: 200383.5938\n",
      "Epoch 76/100\n",
      "149/149 [==============================] - 34s 230ms/step - loss: 215.6631 - mae: 4.9133 - customMetric: 97258.2031 - val_loss: 211.0466 - val_mae: 8.2628 - val_customMetric: 311623.0000\n",
      "Epoch 77/100\n",
      "149/149 [==============================] - 34s 227ms/step - loss: 238.8696 - mae: 6.0322 - customMetric: 100055.7109 - val_loss: 258.1328 - val_mae: 10.8042 - val_customMetric: 574709.5625\n",
      "Epoch 78/100\n",
      "149/149 [==============================] - 34s 226ms/step - loss: 223.2493 - mae: 5.2694 - customMetric: 100533.5078 - val_loss: 216.2249 - val_mae: 7.2942 - val_customMetric: 225774.0312\n",
      "Epoch 79/100\n",
      "149/149 [==============================] - 34s 226ms/step - loss: 217.9641 - mae: 5.0267 - customMetric: 102141.1250 - val_loss: 216.5877 - val_mae: 8.6328 - val_customMetric: 425511.5000\n",
      "Epoch 80/100\n",
      "149/149 [==============================] - 33s 224ms/step - loss: 214.9652 - mae: 4.9331 - customMetric: 114102.8750 - val_loss: 213.8425 - val_mae: 7.5018 - val_customMetric: 241961.4062\n",
      "Epoch 81/100\n",
      "149/149 [==============================] - 33s 224ms/step - loss: 211.7778 - mae: 4.8332 - customMetric: 105341.7344 - val_loss: 212.5337 - val_mae: 7.8789 - val_customMetric: 282325.1562\n",
      "Epoch 82/100\n",
      "149/149 [==============================] - 34s 227ms/step - loss: 213.5452 - mae: 4.8695 - customMetric: 101067.8359 - val_loss: 218.0728 - val_mae: 7.8417 - val_customMetric: 255599.0469\n",
      "Epoch 83/100\n",
      "149/149 [==============================] - 34s 228ms/step - loss: 226.3310 - mae: 5.5309 - customMetric: 103535.3594 - val_loss: 231.4524 - val_mae: 8.7518 - val_customMetric: 471225.7188\n",
      "Epoch 84/100\n",
      "149/149 [==============================] - 34s 227ms/step - loss: 233.2471 - mae: 5.6712 - customMetric: 83303.2188 - val_loss: 247.5513 - val_mae: 9.7167 - val_customMetric: 535283.6875\n",
      "Epoch 85/100\n",
      "149/149 [==============================] - 34s 226ms/step - loss: 226.0038 - mae: 5.3026 - customMetric: 98374.2812 - val_loss: 271.5922 - val_mae: 10.8046 - val_customMetric: 605473.5000\n",
      "Epoch 86/100\n",
      "149/149 [==============================] - 34s 226ms/step - loss: 221.8188 - mae: 5.1273 - customMetric: 88557.7266 - val_loss: 242.5858 - val_mae: 9.7507 - val_customMetric: 505822.5312\n",
      "Epoch 87/100\n",
      "149/149 [==============================] - 34s 226ms/step - loss: 219.7252 - mae: 5.0450 - customMetric: 106401.8125 - val_loss: 265.0150 - val_mae: 10.5512 - val_customMetric: 558619.4375\n",
      "Epoch 88/100\n",
      "149/149 [==============================] - 34s 225ms/step - loss: 217.5919 - mae: 4.9170 - customMetric: 96552.1641 - val_loss: 245.6891 - val_mae: 9.9325 - val_customMetric: 521913.6875\n",
      "Epoch 89/100\n",
      "149/149 [==============================] - 34s 230ms/step - loss: 226.7849 - mae: 5.4700 - customMetric: 94742.1250 - val_loss: 323.2811 - val_mae: 12.7183 - val_customMetric: 798151.6250\n",
      "Epoch 90/100\n",
      "149/149 [==============================] - 34s 225ms/step - loss: 218.0813 - mae: 5.0859 - customMetric: 170104.2500 - val_loss: 291.9874 - val_mae: 11.7566 - val_customMetric: 677537.5000\n",
      "Epoch 91/100\n",
      "149/149 [==============================] - 33s 223ms/step - loss: 212.1038 - mae: 4.8631 - customMetric: 83465.6562 - val_loss: 288.5038 - val_mae: 11.7200 - val_customMetric: 650694.4375\n",
      "Epoch 92/100\n",
      "149/149 [==============================] - 34s 225ms/step - loss: 220.8586 - mae: 5.2669 - customMetric: 79522.2422 - val_loss: 301.4385 - val_mae: 11.9918 - val_customMetric: 730002.0000\n",
      "Epoch 93/100\n",
      "149/149 [==============================] - 34s 226ms/step - loss: 221.9979 - mae: 5.2555 - customMetric: 90260.3438 - val_loss: 211.4033 - val_mae: 7.9162 - val_customMetric: 339935.5938\n",
      "Epoch 94/100\n",
      "149/149 [==============================] - 34s 226ms/step - loss: 221.5512 - mae: 5.1813 - customMetric: 100341.3594 - val_loss: 257.0783 - val_mae: 10.2981 - val_customMetric: 568970.9375\n",
      "Epoch 95/100\n",
      "149/149 [==============================] - 34s 226ms/step - loss: 210.4360 - mae: 4.8341 - customMetric: 90929.2812 - val_loss: 254.0412 - val_mae: 10.3548 - val_customMetric: 520615.1875\n",
      "Epoch 96/100\n",
      "149/149 [==============================] - 34s 228ms/step - loss: 211.0403 - mae: 4.8763 - customMetric: 172793.7500 - val_loss: 245.5367 - val_mae: 9.9827 - val_customMetric: 481824.2500\n",
      "Epoch 97/100\n",
      "149/149 [==============================] - 33s 224ms/step - loss: 216.8960 - mae: 4.9339 - customMetric: 108817.4062 - val_loss: 257.5041 - val_mae: 10.3556 - val_customMetric: 543898.5000\n",
      "Epoch 98/100\n",
      "149/149 [==============================] - 34s 226ms/step - loss: 208.4093 - mae: 4.9269 - customMetric: 113886.2188 - val_loss: 261.4706 - val_mae: 10.2346 - val_customMetric: 467511.1562\n",
      "Epoch 99/100\n",
      "149/149 [==============================] - 34s 226ms/step - loss: 225.1303 - mae: 5.4157 - customMetric: 94715.8516 - val_loss: 256.7043 - val_mae: 10.3312 - val_customMetric: 345645.3438\n",
      "Epoch 100/100\n",
      "149/149 [==============================] - 34s 228ms/step - loss: 232.0227 - mae: 5.6618 - customMetric: 97558.2578 - val_loss: 317.2207 - val_mae: 12.3918 - val_customMetric: 627515.8125\n"
     ]
    }
   ],
   "source": [
    "H_t = []\n",
    "\n",
    "# Using custom loss and gen\n",
    "es = keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.01, patience=25, mode='min', verbose=1, restore_best_weights=True)\n",
    "# H = model.fit(x=x_train, y=y_train, batch_size=64, epochs=300, validation_data=(x_test, y_test), verbose=1, callbacks=[es])\n",
    "# H = model.fit(x=x_train, y=y_train, batch_size=64, epochs=300, shuffle=True, verbose=1, callbacks=[es])\n",
    "# H = model.fit(x=x_train, y=y_train[:,2], batch_size=256, epochs=300, verbose=1, shuffle=True, callbacks=[es])\n",
    "# H_t.append(model.fit(x=x_train, y=y_train[:,2], batch_size=256, epochs=300, verbose=1, shuffle=True, callbacks=[es]).history)\n",
    "# H_t.append(model.fit(x=x_train, y=y_train[:,index], batch_size=256, epochs=300, verbose=1, shuffle=True, callbacks=[es]).history)\n",
    "H_t.append(model.fit(x=x_train, y=y_train, batch_size=2048, epochs=100, verbose=1, validation_data=(x_test, y_test), shuffle=True).history)\n",
    "# H_t.append(model.fit(x=x_train, y=y_train, batch_size=16000, epochs=25, verbose=1, validation_data=(x_test, y_test), shuffle=True).history)\n",
    "# model.fit(x=[x_train[0],x_train[1],x_train[2],np.expand_dims(x_train[3][:,index],-1)], y=y_train[:,index], batch_size=256, epochs=300, verbose=1, shuffle=True)\n",
    "if H == None:\n",
    "  H = H_t[-1]\n",
    "else:\n",
    "  H = concat_hist(H,H_t[-1])\n",
    "final_loss = round(H[\"loss\"][-1],2)\n",
    "# H = model.fit(x=x_train, y=y_train, batch_size=64, epochs=100, validation_data=test_gen, validation_steps=50, validation_batch_size=32, verbose=1)\n",
    "\n",
    "# Example how it kind of looks like\n",
    "# H = model.fit(x=[x_train, invCov, y_train], y=y_train, batch_size=64, epochs=100, verbose=1)\n",
    "\n",
    "# Overfit\n",
    "# es = keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.001, patience=100, mode='min', verbose=1, restore_best_weights=True)\n",
    "# H = model.fit(x=x_train, y=y_train, batch_size=1, epochs=100, verbose=1, callbacks=[es])\n",
    "# H = model.fit(x=x_train, y=y_train, batch_size=1, epochs=100, verbose=1, validation_data=(x_test,y_test), callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZ5XBwDV7MGY"
   },
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_index = 1 # not the right index, dont change this one...\n",
    "date = \"03-15-(2)\"\n",
    "def gen_name(m_type):\n",
    "    global model_index, glob_index, date, final_loss\n",
    "    variable = [\"q_pt\",\"phi\",\"tanl\",\"D\",\"z\"][glob_index]\n",
    "    m_str = \"models/\" + str(date) + \"-2021_\" + str(variable) + \"-\" + str(model_index) + \"_loss=\" + str(final_loss) + \".\" + str(m_type)\n",
    "    model_index+=1 # create a check for if file exists, for now just increment\n",
    "    return m_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "xWvST6o27MYI"
   },
   "outputs": [],
   "source": [
    "# model.save('model.h5', save_format=\"h5\")\n",
    "# TODO check if file exists, increment counter\n",
    "# model.save('drive/MyDrive/Models/RealRNN_1-3-2021_141Ep_Onlytanl-2.h5', save_format=\"h5\")\n",
    "model.save(gen_name(\"h5\"), save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6LGBSia7fg3"
   },
   "source": [
    "## Graph loss and mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "id": "OUPAStLMtq7m",
    "outputId": "d4bada3c-6f91-4a9c-b6d7-d7abe8cc1689"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'H' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9b51d5e7ec19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# print(\"loss: \", H[\"loss\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(\"mae: \", H[\"mae\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(\"val_loss: \", H.history[\"val_loss\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# print(\"val_mae: \", H.history[\"val_mae\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'H' is not defined"
     ]
    }
   ],
   "source": [
    "print(H.keys())\n",
    "# print(\"loss: \", H[\"loss\"])\n",
    "# print(\"mae: \", H[\"mae\"])\n",
    "# print(\"val_loss: \", H.history[\"val_loss\"])\n",
    "# print(\"val_mae: \", H.history[\"val_mae\"])\n",
    "\n",
    "lim = 0\n",
    "\n",
    "fig, ax = plt.subplots(3,1,figsize=(5,15))\n",
    "fig.subplots_adjust(hspace=0.35)\n",
    "\n",
    "ax[0].plot(H[\"loss\"][lim:])\n",
    "ax[0].plot(H[\"val_loss\"][lim:])\n",
    "ax[0].set_title(\"loss vs epoch\", fontsize=20)\n",
    "ax[0].set_xlabel(\"epoch\", fontsize=15)\n",
    "ax[0].set_ylabel(\"loss\", fontsize=15)\n",
    "ax[0].legend([\"train\",\"val\"])\n",
    "ax[0].grid(True)\n",
    "\n",
    "\n",
    "ax[1].plot(H[\"mae\"][lim:])\n",
    "ax[1].plot(H[\"val_mae\"][lim:])\n",
    "ax[1].set_title(\"mae vs epoch\", fontsize=20)\n",
    "ax[1].set_xlabel(\"epoch\", fontsize=15)\n",
    "ax[1].set_ylabel(\"mae\", fontsize=15)\n",
    "ax[1].legend([\"train\",\"val\"])\n",
    "ax[1].grid(True)\n",
    "\n",
    "ax[2].plot(H[\"customMetric\"][lim:])\n",
    "ax[2].plot(H[\"val_customMetric\"][lim:])\n",
    "ax[2].set_title(\"metric vs epoch\", fontsize=20)\n",
    "ax[2].set_xlabel(\"epoch\", fontsize=15)\n",
    "ax[2].set_ylabel(\"metric\", fontsize=15)\n",
    "ax[2].legend([\"train\",\"val\"])\n",
    "ax[2].grid(True)\n",
    "\n",
    "model_index -= 1\n",
    "plt.savefig(gen_name(\"png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303282, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def diff_graph():\n",
    "    fig, ax = plt.subplots(3,1,figsize=(5,15))\n",
    "    fig.subplots_adjust(hspace=0.35)\n",
    "    \n",
    "\n",
    "# pred = model.predict(x_test)\n",
    "pred = model.predict(x_train)\n",
    "print(pred.shape)\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "diff = pred - y_train\n",
    "plt.scatter(y_train,pred,)\n",
    "plt.xlabel(\"true\")\n",
    "plt.ylabel(\"pred\")\n",
    "plt.plot([0,3000],[0,3000])\n",
    "plt.grid(True)\n",
    "# plt.xlim(-10, 1000)\n",
    "# plt.ylim(-10, 500)\n",
    "plt.xlim(-10, 200)\n",
    "plt.ylim(-10, 100)\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(y_train,diff)\n",
    "plt.xlabel(\"true\")\n",
    "plt.ylabel(\"diff\")\n",
    "plt.grid(True)\n",
    "plt.plot([0,3000],[0,0])\n",
    "plt.xlim(0, 1000)\n",
    "plt.ylim(-1000, 200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "an_array = np.array(list(H.items()))\n",
    "save_array = np.array([an_array[0][1],an_array[1][1]])\n",
    "model_index -= 1\n",
    "np.save(gen_name(\"npy\"),save_array,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xw4xzpuKYEld"
   },
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kZHLFMS1YE40",
    "outputId": "09e30fe4-cc1b-444f-83b3-c74d1b923762"
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True, precision=3)\n",
    "from time import sleep\n",
    "\n",
    "for i in range(10):\n",
    "  aax = x_train[0][i:i+1]\n",
    "  oax = x_train[1][i:i+1]\n",
    "  cax = x_train[2][i:i+1]\n",
    "  yax = x_train[3][i:i+1]\n",
    "  aay = y_train[i][index]\n",
    "  pred = model.predict([aax, oax, cax, yax])[0][0]\n",
    "  diff = pred - aay\n",
    "  # print(\"i: \",i)\n",
    "  # print(\"aax:  \",aax[0,0])\n",
    "  print(\"aay:  \",aay)\n",
    "  print(\"pred: \",pred)\n",
    "  # print(\"diff: \",diff)\n",
    "  print(\"\")\n",
    "\n",
    "  # plt.plot(aay[0])\n",
    "  # plt.plot(pred[0])\n",
    "  # plt.show()\n",
    "# [Q/PT, phi, tanl, D, z]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T56J0X6g7O2k"
   },
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zgLQh0jf7Ova"
   },
   "outputs": [],
   "source": [
    "# model.save('drive/MyDrive/RealRNN_1-2-2021_2.h5', save_format=\"h5\")\n",
    "# model = keras.models.load_model('drive/MyDrive/Models/RealRNN_1-3-2021_300Ep_Onlyphi.h5')\n",
    "model = keras.models.load_model('models/03-07-2021_q_pt-1_loss=1688.34.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X72YH9S87cvW"
   },
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(H.keys())\n",
    "# print(\"loss: \", H[\"loss\"])\n",
    "# print(\"mae: \", H[\"mae\"])\n",
    "# print(\"val_loss: \", H.history[\"val_loss\"])\n",
    "# print(\"val_mae: \", H.history[\"val_mae\"])\n",
    "\n",
    "lim = 0\n",
    "\n",
    "if len(H.keys()) > 4:\n",
    "  # fig, ax = plt.subplots(4,1,figsize=(5,20))\n",
    "  fig, ax = plt.subplots(3,1,figsize=(5,15))\n",
    "  fig.subplots_adjust(hspace=0.35)\n",
    "\n",
    "  ax[0].plot(H[\"loss\"][lim:])\n",
    "  # ax[0].plot(H.history[\"val_loss\"][lim:])\n",
    "  ax[0].set_title(\"loss vs epoch\", fontsize=20)\n",
    "  ax[0].set_xlabel(\"epoch\", fontsize=15)\n",
    "  ax[0].set_ylabel(\"loss\", fontsize=15)\n",
    "  # ax[0].set_yscale(\"log\")\n",
    "  ax[0].legend([\"train\",\"val\"])\n",
    "  ax[0].grid(True)\n",
    "\n",
    "\n",
    "  ax[1].plot(H[\"mae\"][lim:])\n",
    "  # ax[1].plot(H.history[\"val_mae\"][lim:])\n",
    "  ax[1].set_title(\"mae vs epoch\", fontsize=20)\n",
    "  ax[1].set_xlabel(\"epoch\", fontsize=15)\n",
    "  ax[1].set_ylabel(\"mae\", fontsize=15)\n",
    "  ax[1].legend([\"train\",\"val\"])\n",
    "  ax[1].grid(True)\n",
    "\n",
    "  ax[2].plot(H[\"q_pt\"][lim:])\n",
    "  ax[2].plot(H[\"phi\"][lim:])\n",
    "  ax[2].plot(H[\"tanl\"][lim:])\n",
    "  ax[2].plot(H[\"D\"][lim:])\n",
    "  ax[2].plot(H[\"z\"][lim:])\n",
    "  ax[2].set_title(\"data vs epoch\", fontsize=20)\n",
    "  ax[2].set_xlabel(\"epoch\", fontsize=15)\n",
    "  ax[2].set_ylabel(\"data\", fontsize=15)\n",
    "  ax[2].legend([\"q_pt\",\"phi\",\"tanl\",\"D\",\"z\"])\n",
    "  # ax[2].legend([\"phi\",\"tanl\",\"D\",\"z\"])\n",
    "  # ax[2].legend([\"phi\",\"D\",\"z\"])\n",
    "  ax[2].grid(True)\n",
    "\n",
    "  # ax[3].plot(H.history[\"val_q_pt\"][lim:])\n",
    "  # ax[3].plot(H.history[\"val_phi\"][lim:])\n",
    "  # ax[3].plot(H.history[\"val_tanl\"][lim:])\n",
    "  # ax[3].plot(H.history[\"val_D\"][lim:])\n",
    "  # ax[3].plot(H.history[\"val_z\"][lim:])\n",
    "  # ax[3].set_title(\"data vs epoch\", fontsize=20)\n",
    "  # ax[3].set_xlabel(\"epoch\", fontsize=15)\n",
    "  # ax[3].set_ylabel(\"data\", fontsize=15)\n",
    "  # ax[3].legend([\"val_q_pt\",\"val_phi\",\"val_tanl\",\"val_D\",\"val_z\"])\n",
    "  # # ax[3].legend([\"val_phi\",\"val_tanl\",\"val_D\",\"val_z\"])\n",
    "  # # ax[3].legend([\"val_phi\",\"val_D\",\"val_z\"])\n",
    "  # ax[3].grid(True)\n",
    "\n",
    "else:\n",
    "  fig, ax = plt.subplots(2,1,figsize=(5,10))\n",
    "  fig.subplots_adjust(hspace=0.35)\n",
    "\n",
    "  ax[0].plot(H[\"loss\"][lim:])\n",
    "  # ax[0].plot(H.history[\"val_loss\"][lim:])\n",
    "  ax[0].set_title(\"loss vs epoch\", fontsize=20)\n",
    "  ax[0].set_xlabel(\"epoch\", fontsize=15)\n",
    "  ax[0].set_ylabel(\"loss\", fontsize=15)\n",
    "  # ax[0].set_yscale(\"log\")\n",
    "  ax[0].legend([\"train\",\"val\"])\n",
    "  ax[0].grid(True)\n",
    "\n",
    "\n",
    "  ax[1].plot(H[\"mae\"][lim:])\n",
    "  # ax[1].plot(H.history[\"val_mae\"][lim:])\n",
    "  ax[1].set_title(\"mae vs epoch\", fontsize=20)\n",
    "  ax[1].set_xlabel(\"epoch\", fontsize=15)\n",
    "  ax[1].set_ylabel(\"mae\", fontsize=15)\n",
    "  ax[1].legend([\"train\",\"val\"])\n",
    "  ax[1].grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "id": "k6XSgSit7dE3",
    "outputId": "b3a1caaf-1b21-4348-bfe7-1315ccb39171"
   },
   "outputs": [],
   "source": [
    "print(H.history.keys())\n",
    "print(\"loss: \", H.history[\"loss\"])\n",
    "print(\"mae: \", H.history[\"mae\"])\n",
    "# print(\"val_loss: \", H.history[\"val_loss\"])\n",
    "# print(\"val_mae: \", H.history[\"val_mae\"])\n",
    "\n",
    "lim = 2\n",
    "\n",
    "fig, ax = plt.subplots(2,1,figsize=(5,10))\n",
    "fig.subplots_adjust(hspace=0.35)\n",
    "\n",
    "ax[0].plot(H.history[\"loss\"][lim:])\n",
    "# ax[0].plot(H.history[\"val_loss\"][lim:])\n",
    "ax[0].set_title(\"loss vs epoch\", fontsize=20)\n",
    "ax[0].set_xlabel(\"epoch\", fontsize=15)\n",
    "ax[0].set_ylabel(\"loss\", fontsize=15)\n",
    "ax[0].set_yscale(\"log\")\n",
    "ax[0].legend([\"train\",\"val\"])\n",
    "ax[0].grid(True)\n",
    "\n",
    "\n",
    "ax[1].plot(H.history[\"mae\"][lim:])\n",
    "# ax[1].plot(H.history[\"val_mae\"][lim:])\n",
    "ax[1].set_title(\"mae vs epoch\", fontsize=20)\n",
    "ax[1].set_xlabel(\"epoch\", fontsize=15)\n",
    "ax[1].set_ylabel(\"mae\", fontsize=15)\n",
    "ax[1].legend([\"train\",\"val\"])\n",
    "ax[1].grid(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UV GRAPHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0][0].shape[0] # (event,hits,18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "for z in range(10):\n",
    "    col = 1\n",
    "    row = 2\n",
    "#     fig, ax = plt.subplots(row,col,figsize=(5*col,5*row))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    gs = fig.add_gridspec(row, col, hspace=0, wspace=0)\n",
    "    ax = gs.subplots(sharex='col', sharey='row')\n",
    "    \n",
    "#     fig.subplots_adjust(hspace=0.5)\n",
    "    u_hits = []\n",
    "    v_hits = []\n",
    "    z_hits = []\n",
    "    for i in range(x_train[0][z].shape[0]):\n",
    "        u_hits.append(x_train[0][z][i][0])\n",
    "        v_hits.append(x_train[0][z][i][1])\n",
    "        z_hits.append(x_train[0][z][i][6])\n",
    "    ax[0].plot(z_hits,u_hits,\"o\")\n",
    "#     ax[0].x_label(\"z_hits\")\n",
    "#     ax[0].y_label(\"u_hits\")\n",
    "    ax[1].plot(z_hits,v_hits,\"o\")\n",
    "#     ax[1].x_label(\"z_hits\")\n",
    "#     ax[1].x_label(\"v_hits\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOi6MC8u7swr"
   },
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pqqb7Riq7tAY"
   },
   "outputs": [],
   "source": [
    "# Maybe copy over previous function and edit that?\n",
    "def graph(pred, true, diff):\n",
    "\n",
    "  values = [\"u\",\"v\",\"sin(v)\",\"cos(v)\",\"sin(u)\",\"cos(u)\",\"s\",\"ds\",\"wire\",\"glayer\",\"z\",\"time\",\"dE_amp\",\"q\"]\n",
    "  limits = [[\"todo\"]]\n",
    "\n",
    "  size = len(values)\n",
    "\n",
    "  fig, axs = plt.subplots(4,size,figsize=(size*5,20))\n",
    "  fig.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "\n",
    "  for i in range(size):\n",
    "    (mu, sigma) = norm.fit(diff[:,i])\n",
    "    print(\"data\" , values[i] ,\" |: mu: \", mu, \"sigma: \" , sigma)\n",
    "    _, bins, _ = axs[0,i].hist(diff[:,i], 20, density=True)\n",
    "    y = norm.pdf(bins, mu, sigma)\n",
    "    l = axs[0,i].plot(bins, y, 'r--', linewidth=2)\n",
    "\n",
    "    axs[0,i].set_title(values[i] + ' diff')\n",
    "    axs[0,i].set_ylabel('freq')\n",
    "    axs[0,i].set_xlabel(values[i] + ' diff')\n",
    "\n",
    "  #--------------------------------------\n",
    "  # PREDICTED VS TRUE\n",
    "  #--------------------------------------\n",
    "    \n",
    "  for i in range(size):\n",
    "    axs[1,i].scatter(true[:,i],pred[:,i])\n",
    "    axs[1,i].grid(True)\n",
    "\n",
    "    axs[1,i].set_title(values[i] + ' (predicted vs true)')\n",
    "    axs[1,i].set_ylabel('pred ' + values[i])\n",
    "    axs[1,i].set_xlabel('true ' + values[i])\n",
    "\n",
    "    # axs[1,i].set_xlim(limits[i])\n",
    "    # axs[1,i].set_ylim(limits[i])\n",
    "    # axs[1,i].plot(limits[i],limits[i], color='b')\n",
    "\n",
    "  #--------------------------------------\n",
    "  # DIFFERENCE VS TRUE\n",
    "  #--------------------------------------\n",
    "\n",
    "  for i in range(size):\n",
    "    axs[2,i].scatter(true[:,i],diff[:,i])\n",
    "    l, r = axs[2,i].get_xlim()\n",
    "    axs[2,i].hlines(0, l, r)\n",
    "    axs[2,i].grid(True)\n",
    "\n",
    "    axs[2,i].set_title(values[i] + ' (difference vs true)')\n",
    "    axs[2,i].set_ylabel('diff ' + values[i])\n",
    "    axs[2,i].set_xlabel('true ' + values[i])\n",
    "\n",
    "  #--------------------------------------\n",
    "  # DIFFERENCE VS TRUE 2D HIST\n",
    "  #--------------------------------------\n",
    "\n",
    "  for i in range(size):\n",
    "    axs[3,i].hist2d(true[:,i],diff[:,i],bins=20)\n",
    "\n",
    "    axs[2,i].set_title(values[i] + ' (difference vs true)')\n",
    "    axs[2,i].set_ylabel('diff ' + values[i])\n",
    "    axs[2,i].set_xlabel('true ' + values[i])\n",
    "\n",
    "  fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHuUmXPCiXt9"
   },
   "outputs": [],
   "source": [
    "def gen_test_data(x_test, y_test, size=1000):\n",
    "  pred = model.predict(x_test)\n",
    "  diff = pred - y_test\n",
    "  return pred, y_test, diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2AMRhD6Wi7Xh"
   },
   "outputs": [],
   "source": [
    "graph(gen_test_data(x_test, y_test));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAUyMneo7Xj1"
   },
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sBsHjTgG7X2y"
   },
   "outputs": [],
   "source": [
    "# make test function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWkYEQvFZ7HC"
   },
   "source": [
    "# Verification of proper data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqKxKcOQYEO4"
   },
   "source": [
    "## Using Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ml3HHzoEaAhr"
   },
   "outputs": [],
   "source": [
    "aax, aay = next(train_gen)\n",
    "print(aax.shape)\n",
    "print(aay.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gv72llYMaUYd"
   },
   "outputs": [],
   "source": [
    "print(\"x\",aax[0])\n",
    "print(\"y\",aay[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcwDKKLLe079"
   },
   "source": [
    "## Non Genenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DlU3tRGpYxQV",
    "outputId": "a24ded2d-d1d0-4555-84a9-428edf5b2e7d"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "  aax = x_train[i]\n",
    "  aay = y_train[i]\n",
    "  # print(aax.shape)\n",
    "  # print(aay.shape)\n",
    "  # print(\"x\",aax)\n",
    "  print(\"y\",aay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCpP2wsfdeGl"
   },
   "source": [
    "## Graphs of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAxLbw94GYzm"
   },
   "source": [
    "### filter_ignore\n",
    "\n",
    "Filters out large and small values and graphs them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FiUKfbtfAoLm"
   },
   "outputs": [],
   "source": [
    "def filter_ignore(var,min=None,max=None,bins=25,ylog=False,xlog=False,cut=True):\n",
    "  list_ignore = []\n",
    "\n",
    "  print(\"--== {} ==--\\n\".format(var))\n",
    "\n",
    "  largest = 0\n",
    "  smallest = 0\n",
    "  for i in range(len(csv_train[var])):\n",
    "    if csv_train[var][i] > csv_train[var][largest]:\n",
    "      largest = i\n",
    "    if csv_train[var][i] < csv_train[var][smallest]:\n",
    "      smallest = i\n",
    "  print(\"largest value:  ({}, {:.3f})\".format(largest,csv_train[var][largest]))\n",
    "  print(\"smallest value: ({}, {:.3f})\".format(smallest,csv_train[var][smallest]))\n",
    "\n",
    "  print(\"\")\n",
    "\n",
    "  if min:\n",
    "    for i in range(len(csv_train[var])):\n",
    "      if csv_train[var][i] < min:\n",
    "        list_ignore.append(i)\n",
    "    print(\"min IDs to ignore for '{}':\".format(var))\n",
    "    print(csv_train[var][list_ignore])\n",
    "    print(\"\")\n",
    "  if max:\n",
    "    for i in range(len(csv_train[var])):\n",
    "      if csv_train[var][i] > max:\n",
    "        list_ignore.append(i)\n",
    "    print(\"max IDs to ignore for '{}':\".format(var))\n",
    "    print(csv_train[var][list_ignore])\n",
    "    print(\"\")\n",
    "  if min and max:\n",
    "    print(\"total IDs to ignore for '{}':\".format(var))\n",
    "    print(csv_train[var][list_ignore])\n",
    "    print(\"\")\n",
    "    plt.hist(csv_train[var],range=[min,max],bins=bins)\n",
    "  elif min:\n",
    "    plt.hist(csv_train[var],range=[min,csv_train[var][largest]],bins=bins)\n",
    "  elif max:\n",
    "    plt.hist(csv_train[var],range=[csv_train[var][smallest],max],bins=bins)\n",
    "  else:\n",
    "    plt.hist(csv_train[var],bins=bins)\n",
    "  \n",
    "  plt.title(var)\n",
    "  if cut:\n",
    "    plt.xlim(left=min,right=max)\n",
    "  if ylog:\n",
    "    plt.yscale(\"log\")\n",
    "  if xlog:\n",
    "    plt.xscale(\"log\")\n",
    "  plt.show()\n",
    "  return list_ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "BwsJ0YIoBiew",
    "outputId": "962724f0-0845-4ab5-8b27-043de6744e44"
   },
   "outputs": [],
   "source": [
    "filter_ignore(\"q_over_pt\",min=-4000,bins=30,ylog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "2Wyjq07YGjBF",
    "outputId": "9a82db49-7e7e-49aa-8d4b-a0da738ec1f5"
   },
   "outputs": [],
   "source": [
    "filter_ignore(\"tanl\",max=1000,bins=25,ylog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xauTTOyrHPyT"
   },
   "outputs": [],
   "source": [
    "rms_ignore = filter_ignore(\"rms\",max=0.1,bins=25,ylog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "ERa-RZDbN6Hm",
    "outputId": "ac4577c9-f719-47d4-bc16-8fdbb7e413a5"
   },
   "outputs": [],
   "source": [
    "# 'q_over_pt', 'phi', 'tanl', 'D', 'z'\n",
    "# filter_ignore(\"D\", min=-200, ylog=True,bins=25)\n",
    "filter_ignore(\"z\",bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UBO9wKCH2ePH"
   },
   "outputs": [],
   "source": [
    "csv_train.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yc3WNfPaYwaL"
   },
   "source": [
    "### 1D Hist of all Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "id": "2VqlQxZRgTB7",
    "outputId": "2a5ce7d3-1665-4d71-80f5-5b7ed7ceb673"
   },
   "outputs": [],
   "source": [
    "plt.hist(csv_train[\"phi\"],bins=50) # -3 to 3, even distrib\n",
    "plt.title(\"phi\")\n",
    "plt.show()\n",
    "# ---\n",
    "plt.hist(csv_train[\"D\"],range=[-3000,80],bins=25) # -3000 to 50, but val in 65\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"D\")\n",
    "plt.show()\n",
    "# ---\n",
    "plt.hist(csv_train[\"z\"],bins=100)\n",
    "plt.title(\"z\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(csv_train[\"cov_44\"],range=[0,1000],bins=25)\n",
    "# plt.yscale(\"log\")\n",
    "plt.title(\"cov_44\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TbqYK55L05mB",
    "outputId": "81dc2a8d-b572-4505-983a-8958a9bea8b6"
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(2,1,figsize=(5,10))\n",
    "# fig.subplots_adjust(hspace=0.35)\n",
    "\n",
    "plt.hist(csv_train[\"cov_00\"],range=[0,1e8],bins=25) # 0 to 1e13\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"cov_00\")\n",
    "plt.show()\n",
    "# ---\n",
    "plt.hist(csv_train[\"cov_01\"],bins=25) # -1e6 to over 1e5\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"cov_44\")\n",
    "plt.show()\n",
    "# ---\n",
    "plt.hist(csv_train[\"chisq\"],bins=25) # 0 to 200\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"chisq\")\n",
    "plt.show()\n",
    "# ---\n",
    "plt.hist(csv_train[\"Ndof\"],range=[0,44],bins=45) # ? this one weird 0 to ~43\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Ndof\")\n",
    "plt.show()\n",
    "# ---\n",
    "plt.hist(csv_train[\"rms\"],range=[0,0.1],bins=25) # \n",
    "# plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"rms\")\n",
    "plt.show()\n",
    "# ---\n",
    "# plt.hist(csv_train[\"t_start_cntr\"],bins=25) # -60 to ~50\n",
    "plt.hist(csv_train[csv_train[\"t_start_cntr_valid\"] == 1][\"t_start_cntr\"],bins=25) # -60 to ~50\n",
    "plt.title(\"t_start_cntr\")\n",
    "plt.show()\n",
    "\n",
    "# plt.hist(csv_train[\"t_tof\"],bins=25) # ~-120 to ~175\n",
    "plt.hist(csv_train[csv_train[\"t_tof_valid\"] == 1][\"t_tof\"],bins=25) # ~-120 to ~175\n",
    "plt.title(\"t_tof\")\n",
    "plt.show()\n",
    "plt.hist(csv_train[\"t_bcal\"],bins=25) # ~-22 to 20\n",
    "plt.title(\"t_bcal\")\n",
    "plt.show()\n",
    "plt.hist(csv_train[\"t_fcal\"],bins=25) # ~-100 to ~75\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"t_fcal\")\n",
    "plt.show()\n",
    "# ---\n",
    "plt.hist(csv_train[\"t_start_cntr_valid\"],bins=25) # a lot more 0s\n",
    "plt.title(\"t_start_cntr_valid\")\n",
    "plt.show()\n",
    "plt.hist(csv_train[\"t_tof_valid\"],bins=25) # about 5050\n",
    "plt.title(\"t_tof_valid\")\n",
    "plt.show()\n",
    "plt.hist(csv_train[\"t_bcal_valid\"],bins=25) # almost all 0s\n",
    "plt.title(\"t_bcal_valid\")\n",
    "plt.show()\n",
    "plt.hist(csv_train[\"t_fcal_valid\"],bins=25) # almost all 0s\n",
    "plt.title(\"t_fcal_valid\")\n",
    "plt.show()\n",
    "# ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbzN70C9MCrQ"
   },
   "source": [
    "### 1D Hist of Hit1 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "VGzHLbKsLUZ9",
    "outputId": "0e1a0a14-8881-439d-c2f3-f0ec09006cc4"
   },
   "outputs": [],
   "source": [
    "plt.hist(csv_train[\"hit1_u\"],bins=25) # -42 to 42\n",
    "plt.title(\"hit1_u\")\n",
    "plt.show()\n",
    "plt.hist(csv_train[\"hit1_v\"],bins=25) # -42 to 42\n",
    "plt.title(\"hit1_v\")\n",
    "plt.show()\n",
    "# plt.hist(csv_train[\"hit1_sinv\"],bins=25) # most are 0.96603 almost all are around that though\n",
    "# plt.title(\"hit1_sinv\")\n",
    "# plt.show()\n",
    "# plt.hist(csv_train[\"hit1_cosv\"],bins=25) # most -0.2585\n",
    "# plt.title(\"hit1_cosv\")\n",
    "# plt.show()\n",
    "# plt.hist(csv_train[\"hit1_sinu\"],bins=25) # most 0.96585\n",
    "# plt.title(\"hit1_sinu\")\n",
    "# plt.show()\n",
    "# plt.hist(csv_train[\"hit1_cosu\"],bins=25) # most 0.2591\n",
    "# plt.title(\"hit1_cosu\")\n",
    "# plt.show()\n",
    "plt.hist(csv_train[\"hit1_s\"],bins=25) # -42 to 42\n",
    "plt.title(\"hit1_s\")\n",
    "plt.show()\n",
    "plt.hist(csv_train[\"hit1_ds\"],bins=25) # 0.01 to 0.04\n",
    "plt.title(\"hit1_ds\")\n",
    "plt.show()\n",
    "plt.hist(csv_train[\"hit1_wire\"],bins=101,range=[0,100]) # 0 to 100\n",
    "plt.title(\"hit1_wire\")\n",
    "plt.show()\n",
    "plt.hist(csv_train[\"hit1_glayer\"],bins=25,range=[0,26]) # 6 to 23\n",
    "plt.title(\"hit1_glayer\")\n",
    "plt.show()\n",
    "plt.hist(csv_train[\"hit1_z\"],bins=25) # spaced out between 180 and 340\n",
    "plt.title(\"hit1_z\")\n",
    "plt.show()\n",
    "plt.hist(csv_train[\"hit1_time\"],bins=25) # -75 to 270\n",
    "plt.title(\"hit1_time\")\n",
    "plt.show()\n",
    "plt.hist(csv_train[\"hit1_dE_amp\"],bins=25) # 0 to 2e-7\n",
    "plt.title(\"hit1_dE_amp\")\n",
    "plt.show()\n",
    "plt.hist(csv_train[\"hit1_q\"],bins=25) # 0 to 85\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"hit1_q\")\n",
    "plt.show()\n",
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxIRSBXpYzU7"
   },
   "source": [
    "### 2D Scatters of various data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "8hgtNdVxY-4_",
    "outputId": "9e12924e-9cb0-492c-fcbb-8cbc7ed4680e"
   },
   "outputs": [],
   "source": [
    "plt.scatter(csv_train[\"tanl\"],abs(csv_train[\"q_over_pt\"]),s=0.01) # a lot more 0s\n",
    "plt.title(\"q_over_pt vs tanl\")\n",
    "plt.xlabel(\"tanl\")\n",
    "plt.ylabel(\"q_over_pt\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "4pjOeJd85uWM",
    "outputId": "887b1312-0399-4223-ff5d-576875baa7e8"
   },
   "outputs": [],
   "source": [
    "# all create a plus sign\n",
    "plt.scatter(csv_train[\"t_start_cntr\"],csv_train[\"t_tof\"]) # a lot more 0s\n",
    "plt.title(\"t_tof vs t_start_cntr\")\n",
    "plt.xlabel(\"t_start_cntr\")\n",
    "plt.ylabel(\"t_tof\")\n",
    "plt.show()\n",
    "\n",
    "# plt.hist(csv_train[\"t_start_cntr\"],bins=25) # -60 to ~50\n",
    "# plt.hist(csv_train[\"t_tof\"],bins=25) # ~-120 to ~175\n",
    "# plt.hist(csv_train[\"t_bcal\"],bins=25) # ~-22 to 20\n",
    "# plt.hist(csv_train[\"t_fcal\"],bins=25) # ~-100 to ~75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "IFF2_7npOseE",
    "outputId": "8e8bec48-6610-41d1-8faa-64814bb75af9"
   },
   "outputs": [],
   "source": [
    "plt.hist(csv_train[\"hit1_glayer\"],bins=24)\n",
    "plt.hist(csv_train[\"hit2_glayer\"],bins=24)\n",
    "plt.hist(csv_train[\"hit3_glayer\"],bins=24)\n",
    "plt.hist(csv_train[\"hit4_glayer\"],bins=24)\n",
    "plt.hist(csv_train[\"hit5_glayer\"],bins=24)\n",
    "plt.hist(csv_train[\"hit6_glayer\"],bins=24)\n",
    "plt.hist(csv_train[\"hit10_glayer\"],bins=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdRImNvKZ0Fa"
   },
   "source": [
    "### 2D Scatters of various hit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4mxK94YV2FM2"
   },
   "outputs": [],
   "source": [
    "# Oval\n",
    "plt.scatter(csv_train[\"hit1_u\"],csv_train[\"hit1_v\"]) # -3 to 3, even distrib\n",
    "plt.title(\"v vs u\")\n",
    "plt.xlabel(\"u\")\n",
    "plt.ylabel(\"v\")\n",
    "plt.show()\n",
    "\n",
    "# like a flame\n",
    "plt.scatter(csv_train[\"hit1_s\"],csv_train[\"hit1_ds\"]) # -3 to 3, even distrib\n",
    "plt.title(\"ds vs s\")\n",
    "plt.xlabel(\"s\")\n",
    "plt.ylabel(\"ds\")\n",
    "plt.show()\n",
    "\n",
    "# hit1_wire, with single letters, forms an oval\n",
    "plt.scatter(csv_train[\"hit1_wire\"],csv_train[\"hit1_s\"]) # -3 to 3, even distrib\n",
    "plt.title(\"hit1_s vs hit1_wire\")\n",
    "plt.xlabel(\"hit1_wire\")\n",
    "plt.ylabel(\"hit1_s\")\n",
    "plt.show()\n",
    "\n",
    "# go up in steps\n",
    "plt.scatter(csv_train[\"hit1_glayer\"],csv_train[\"hit1_z\"]) # -3 to 3, even distrib\n",
    "plt.title(\"z vs glayer\")\n",
    "plt.xlabel(\"glayer\")\n",
    "plt.ylabel(\"z\")\n",
    "plt.show()\n",
    "\n",
    "# 1:1\n",
    "plt.scatter(csv_train[\"hit1_q\"],csv_train[\"hit1_dE_amp\"]) # -3 to 3, even distrib\n",
    "plt.title(\"dE_amp vs q\")\n",
    "plt.xlabel(\"q\")\n",
    "plt.ylabel(\"dE_amp\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bhNGqPbNQ8fX"
   },
   "outputs": [],
   "source": [
    "aax = \n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dM6aySx8xO-"
   },
   "source": [
    "# Depricated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ie8Rhqf765N5"
   },
   "source": [
    "## Non Custom Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CpJHFBHy74vp"
   },
   "outputs": [],
   "source": [
    "# --==Not in use?==--\n",
    "# lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=1e-3,\n",
    "#     decay_steps=10000,\n",
    "#     decay_rate=0.8)\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "nInput = 10\n",
    "\n",
    "# inputs = keras.layers.Input((None,nInput))\n",
    "# print(\"train shape of one batch:\", x_train.shape[1:])\n",
    "\n",
    "# --==Set seed to get identical results==-- begin\n",
    "# from tensorflow.random import set_seed\n",
    "# np.random.seed(1)\n",
    "# set_seed(2)\n",
    "# --==Set seed to get identical results==-- end\n",
    "\n",
    "\n",
    "#--==Set Weights==--\n",
    "# loss_weights = [1/(sd**2)]\n",
    "# loss_weights = np.array(loss_weights)/sum(loss_weights)\n",
    "# model.compile(optimizer=optimizer, loss=\"mse\", loss_weights=loss_weights, metrics=[\"mae\"])\n",
    "\n",
    "inputs = keras.Input((None,nInput),ragged=True)\n",
    "\n",
    "# --==Choose model==--\n",
    "# x = model(inputs)\n",
    "# x = model_timeless(inputs)\n",
    "# x = RNNTime(inputs)\n",
    "x = RNNTimeless(inputs)\n",
    "# x = RNNTimeStateful(inputs)\n",
    "\n",
    "\n",
    "outs = {\n",
    "    \"q_pt\":Dense(1, name=\"q_pt\")(x),\n",
    "    \"phi\":Dense(1, name=\"phi\")(x),\n",
    "    \"tanl\":Dense(1, name=\"tanl\")(x),\n",
    "    \"D\":Dense(1, name=\"D\")(x),\n",
    "    \"z\":Dense(1, name=\"z\")(x)\n",
    "}\n",
    "\n",
    "y_dict = {\n",
    "    \"q_pt\":y_train[:,0],\n",
    "    \"phi\":y_train[:,1],\n",
    "    \"tanl\":y_train[:,2],\n",
    "    \"D\":y_train[:,3],\n",
    "    \"z\":y_train[:,4]\n",
    "}\n",
    "\n",
    "\n",
    "# model = keras.Model(inputs=inputs, outputs=x, name=\"RNNModel\")\n",
    "# model = keras.Model(inputs=inputs, outputs=x, name=\"RNNModel\")\n",
    "model = keras.Model(inputs=inputs, outputs=outs, name=\"RNNModel\")\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hw07sS4jFgJI"
   },
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.01, patience=50, mode='min', verbose=1, restore_best_weights=True)\n",
    "rag_x = x_train[0]\n",
    "H = model.fit(x=rag_x, y=y_dict, batch_size=64, epochs=100, verbose=1, callbacks=[es])\n",
    "\n",
    "# Overfit\n",
    "# es = keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.001, patience=100, mode='min', verbose=1, restore_best_weights=True)\n",
    "# H = model.fit(x=x_train[:10], y=y_train[:10], batch_size=1, epochs=200, verbose=1, shuffle=True, callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMcu1m3k7rHK"
   },
   "source": [
    "## Versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUBj5VjBuyL9"
   },
   "source": [
    "### V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7-v4CJdyQk8",
    "outputId": "940df566-bd20-4356-a2cb-da3bcfaa5fd9"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "#--------------------------------------------\n",
    "# Define custom loss function \n",
    "def customLoss(y_true, y_pred, invcov):\n",
    "  # print(type(y_true))    #<class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>\n",
    "\n",
    "\n",
    "  # print(y_pred)\n",
    "\n",
    "  y_pred_a = []\n",
    "  for k in y_pred.keys():\n",
    "    y_pred_a.append(np.squeeze(y_pred[k]))\n",
    "\n",
    "  y_pred = np.array(y_pred_a).astype(\"float64\")\n",
    "  y_pred = tf.transpose(y_pred, perm=(1,0))\n",
    "  # print(y_pred.shape)\n",
    "  print(y_pred)\n",
    "\n",
    "  batch_size = tf.shape(y_pred)[0]\n",
    "  print('y_pred shape: ' + str(y_pred.shape) )  # y_pred dict shape of each is (batch, 1)\n",
    "  print('y_true shape: ' + str(y_true.shape) )  # y_true shape is (batch, 5)\n",
    "  print('invcov shape: ' + str(invcov.shape) )  # invcov shape is (batch, 25)\n",
    "  \n",
    "  y_pred = K.reshape(y_pred, (batch_size, 5,1)) # y_pred  shape is now (batch, 5,1)\n",
    "  y_true = K.reshape(y_true, (batch_size, 5,1)) # y_state shape is now (batch, 5,1)\n",
    "  invcov = K.reshape(invcov, (batch_size, 5,5)) # invcov  shape is now (batch, 5,5)\n",
    "  \n",
    "  # n.b. we must use tf.transpose here an not K.transpose since the latter does not allow perm argument\n",
    "  invcov = tf.transpose(invcov, perm=[0,2,1])     # invcov shape is now (batch, 5,5)\n",
    "  \n",
    "  # Difference between prediction and true state vectors\n",
    "  y_diff = y_pred - y_true\n",
    "\n",
    "  # n.b. use \"batch_dot\" and not \"dot\"!\n",
    "  y_dot = K.batch_dot(invcov, y_diff)           # y_dot shape is (batch,5,1)\n",
    "  y_loss = K.reshape(y_dot, (batch_size, 5))  # y_dot shape is now (batch,5)\n",
    "\n",
    "  y_dict = {\n",
    "      \"q_pt\":y_loss[:,0],\n",
    "      \"phi\":y_loss[:,1],\n",
    "      \"tanl\":y_loss[:,2],\n",
    "      \"D\":y_loss[:,3],\n",
    "      \"z\":y_loss[:,4],\n",
    "  }\n",
    "\n",
    "  # y_dot = K.reshape(y_dot, (batch_size, 1, 5))  # y_dot shape is now (batch,1,5)\n",
    "  # y_loss = K.batch_dot(y_dot, y_diff)           # y_loss shape is (batch,1,1)\n",
    "  # y_loss = K.reshape(y_loss, (batch_size,))     # y_loss shape is now (batch)\n",
    "  return y_dict\n",
    "#--------------------------------------------\n",
    "# Test loss function\n",
    "# x_test = y_train[0]\n",
    "x_test = x_train[2][0:4]\n",
    "y_test = model.predict([x_train[0][0:4],x_train[1][0:4],x_train[2][0:4]])\n",
    "inconv_test = x_train[1][0:4]\n",
    "\n",
    "# for k in y_test.keys():\n",
    "#   y_test[k] = np.squeeze(y_test[k])\n",
    "# print(y_test)\n",
    "\n",
    "# print(y_test)\n",
    "# y_test_a = []\n",
    "# for k in y_test.keys():\n",
    "#   y_test_a.append(y_test[k])\n",
    "# y_test = np.squeeze(np.array(y_test_a))\n",
    "# print(y_test.shape)\n",
    "# print(y_test)\n",
    "\n",
    "# loss = K.eval(customLoss(K.variable([x_test,x_test,x_test]), K.variable([y_test,y_test,y_test]), K.variable([inconv_test,inconv_test,inconv_test])))\n",
    "loss = K.eval(customLoss(x_test, y_test, inconv_test))\n",
    "# print('loss shape: '    + str(loss.shape)    )\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAP0kzRvu2hz"
   },
   "source": [
    "### V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U7mcvkxuuweK",
    "outputId": "1197158f-904e-4103-f45a-2f015a71f639"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "#--------------------------------------------\n",
    "# Define custom loss function \n",
    "def customLoss(q_pt_true, phi_true, tanl_true, D_true, z_true, q_pt_pred, phi_pred, tanl_pred, D_pred, z_pred, invcov):\n",
    "\n",
    "\n",
    "  y_pred = [q_pt_pred, phi_pred, tanl_pred, D_pred, z_pred]\n",
    "  # y_pred = np.array(y_pred).astype(\"float64\")\n",
    "  y_pred = tf.transpose(y_pred, perm=(1,0))\n",
    "  y_pred = tf.cast(y_pred, \"float64\")\n",
    "\n",
    "  y_true = [q_pt_true, phi_true, tanl_true, D_true, z_true]\n",
    "  # y_true = np.array(y_true).astype(\"float64\")\n",
    "  y_true = tf.transpose(y_true, perm=(1,0))\n",
    "  y_true = tf.cast(y_true, \"float64\")\n",
    "\n",
    "  batch_size = tf.shape(y_pred)[0]\n",
    "  print('y_pred shape: ' + str(y_pred.shape) )  # y_pred dict shape of each is (batch, 1)\n",
    "  print('y_true shape: ' + str(y_true.shape) )  # y_true shape is (batch, 5)\n",
    "  print('invcov shape: ' + str(invcov.shape) )  # invcov shape is (batch, 25)\n",
    "  \n",
    "  y_pred = K.reshape(y_pred, (batch_size, 5,1)) # y_pred  shape is now (batch, 5,1)\n",
    "  y_true = K.reshape(y_true, (batch_size, 5,1)) # y_state shape is now (batch, 5,1)\n",
    "  invcov = K.reshape(invcov, (batch_size, 5,5)) # invcov  shape is now (batch, 5,5)\n",
    "  \n",
    "  # n.b. we must use tf.transpose here an not K.transpose since the latter does not allow perm argument\n",
    "  invcov = tf.transpose(invcov, perm=[0,2,1])     # invcov shape is now (batch, 5,5)\n",
    "  \n",
    "  # Difference between prediction and true state vectors\n",
    "  y_diff = y_pred - y_true\n",
    "\n",
    "  # n.b. use \"batch_dot\" and not \"dot\"!\n",
    "  y_dot = K.batch_dot(invcov, y_diff)           # y_dot shape is (batch,5,1)\n",
    "  y_loss = K.reshape(y_dot, (batch_size, 5))  # y_dot shape is now (batch,5)\n",
    "\n",
    "  y_dict = {\n",
    "      \"q_pt\":y_loss[:,0],\n",
    "      \"phi\":y_loss[:,1],\n",
    "      \"tanl\":y_loss[:,2],\n",
    "      \"D\":y_loss[:,3],\n",
    "      \"z\":y_loss[:,4],\n",
    "  }\n",
    "\n",
    "  # y_dot = K.reshape(y_dot, (batch_size, 1, 5))  # y_dot shape is now (batch,1,5)\n",
    "  # y_loss = K.batch_dot(y_dot, y_diff)           # y_loss shape is (batch,1,1)\n",
    "  # y_loss = K.reshape(y_loss, (batch_size,))     # y_loss shape is now (batch)\n",
    "  return y_dict\n",
    "#--------------------------------------------\n",
    "# Test loss function\n",
    "# x_test = y_train[0]\n",
    "x_test = x_train[2][0:4]\n",
    "y_test = model.predict([x_train[0][0:4],x_train[1][0:4],x_train[2][0:4]])\n",
    "inconv_test = x_train[1][0:4]\n",
    "\n",
    "y_test_a = []\n",
    "for k in y_test.keys():\n",
    "  y_test_a.append(y_test[k])\n",
    "y_test = np.squeeze(np.array(y_test_a))\n",
    "y_test = np.swapaxes(y_test, 0, 1)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "# loss = K.eval(customLoss(K.variable([x_test,x_test,x_test]), K.variable([y_test,y_test,y_test]), K.variable([inconv_test,inconv_test,inconv_test])))\n",
    "loss = K.eval(customLoss(x_test[:,0],x_test[:,1],x_test[:,2],x_test[:,3],x_test[:,4], y_test[:,0], y_test[:,1],y_test[:,2],y_test[:,3],y_test[:,4], inconv_test))\n",
    "# print('loss shape: '    + str(loss.shape)    )\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kuUpxAuz1sz"
   },
   "source": [
    "### V4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRUvQVjHAD2U"
   },
   "source": [
    "So, we have the prediction and true vector\n",
    "\n",
    "$$\n",
    "y_{pred}=\n",
    "\\begin{bmatrix}\n",
    "q\\_pt \\\\ phi \\\\ tanl \\\\ D \\\\ z\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We have the inverse covariance matrix, we'll label it $C^{-1}$:\n",
    "\n",
    "and $y_p = y_{predict}$\n",
    "\n",
    "$$\n",
    "C^{-1} = \n",
    "\\begin{bmatrix}\n",
    "qq & qp & qt & qd & qz \\\\\n",
    "qp & pp & pt & pd & pz \\\\\n",
    "qt & pt & tt & td & tz \\\\\n",
    "qd & pd & td & dd & dz \\\\\n",
    "qz & pz & tz & dz & zz \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Thus, the formula before was:\n",
    "\n",
    "$$\n",
    "loss = C^{-1} \\cdot \\vec{y_p}  \\cdot \\vec{y_p}\n",
    "$$\n",
    "\n",
    "$$\n",
    "  y_{dot} =\n",
    "  \\begin{bmatrix}\n",
    "    qq & qp & qt & qd & qz \\\\\n",
    "    qp & pp & pt & pd & pz \\\\\n",
    "    qt & pt & tt & td & tz \\\\\n",
    "    qd & pd & td & dd & dz \\\\\n",
    "    qz & pz & tz & dz & zz \n",
    "  \\end{bmatrix} \n",
    "  \\cdot\n",
    "  \\begin{bmatrix}\n",
    "    q\\_pt \\\\ phi \\\\ tanl \\\\ D \\\\ z\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "  y_{dot} = \n",
    "  \\begin{bmatrix}\n",
    "    qq*q\\_pt + qp*phi + qt*tanl + qd*D + qz*z \\\\\n",
    "    qp*q\\_pt + pp*phi + pt*tanl + pd*D + pz*z \\\\\n",
    "    qt*q\\_pt + pt*phi + tt*tanl + td*D + tz*z \\\\\n",
    "    qd*q\\_pt + pd*phi + td*tanl + dd*D + dz*z \\\\\n",
    "    qz*q\\_pt + dz*phi + tz*tanl + pz*D + zz*z\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Now, working on the output split for each variable, im looking for ways to seperate the variables after that operation.\n",
    "So maybe just sum the q_pt column of the matrix and multiply by q_pt?\n",
    "\n",
    "Maybe this would work? :\n",
    "\n",
    "$$\n",
    "loss_{q\\_pt} =  y_p^{q\\_pt} * \\sum_{i=0}^{4} C^{-1}_{qi}\n",
    "$$\n",
    "\n",
    "Where $C^{-1}_q$ is one row or column of the matrix of that variable\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8shIh2axz1g_",
    "outputId": "bbc9620f-ee91-4ed5-a02c-8e29e698e46b"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "#--------------------------------------------\n",
    "# Define custom loss function \n",
    "def customLoss(y_true, y_pred, invcov):\n",
    "  # print(type(y_true))    #<class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>\n",
    "\n",
    "  # print(y_pred)\n",
    "\n",
    "  # Theoretically:\n",
    "  # K.dot(invcov[0,:] * q_pt,q_pt)    # ?\n",
    "  \n",
    "\n",
    "\n",
    "  y_pred_a = []\n",
    "  for k in y_pred.keys():\n",
    "    y_pred_a.append(np.squeeze(y_pred[k]))\n",
    "\n",
    "  y_pred = np.array(y_pred_a).astype(\"float64\")\n",
    "  y_pred = tf.transpose(y_pred, perm=(1,0))\n",
    "  # print(y_pred.shape)\n",
    "  print(y_pred)\n",
    "\n",
    "  batch_size = tf.shape(y_pred)[0]\n",
    "  print('y_pred shape: ' + str(y_pred.shape) )  # y_pred dict shape of each is (batch, 1)\n",
    "  print('y_true shape: ' + str(y_true.shape) )  # y_true shape is (batch, 5)\n",
    "  print('invcov shape: ' + str(invcov.shape) )  # invcov shape is (batch, 25)\n",
    "  \n",
    "  y_pred = K.reshape(y_pred, (batch_size, 5,1)) # y_pred  shape is now (batch, 5,1)\n",
    "  y_true = K.reshape(y_true, (batch_size, 5,1)) # y_state shape is now (batch, 5,1)\n",
    "  invcov = K.reshape(invcov, (batch_size, 5,5)) # invcov  shape is now (batch, 5,5)\n",
    "  \n",
    "  # n.b. we must use tf.transpose here an not K.transpose since the latter does not allow perm argument\n",
    "  invcov = tf.transpose(invcov, perm=[0,2,1])     # invcov shape is now (batch, 5,5)\n",
    "  \n",
    "  # Difference between prediction and true state vectors\n",
    "  y_diff = y_pred - y_true\n",
    "\n",
    "  # n.b. use \"batch_dot\" and not \"dot\"!\n",
    "  y_dot = K.batch_dot(invcov, y_diff)           # y_dot shape is (batch,5,1)\n",
    "  y_loss = K.reshape(y_dot, (batch_size, 5))  # y_dot shape is now (batch,5)\n",
    "\n",
    "  y_dict = {\n",
    "      \"q_pt\":y_loss[:,0],\n",
    "      \"phi\":y_loss[:,1],\n",
    "      \"tanl\":y_loss[:,2],\n",
    "      \"D\":y_loss[:,3],\n",
    "      \"z\":y_loss[:,4],\n",
    "  }\n",
    "\n",
    "  # y_dot = K.reshape(y_dot, (batch_size, 1, 5))  # y_dot shape is now (batch,1,5)\n",
    "  # y_loss = K.batch_dot(y_dot, y_diff)           # y_loss shape is (batch,1,1)\n",
    "  # y_loss = K.reshape(y_loss, (batch_size,))     # y_loss shape is now (batch)\n",
    "  return y_dict\n",
    "#--------------------------------------------\n",
    "# Test loss function\n",
    "# x_test = y_train[0]\n",
    "x_test = x_train[2][0:4]\n",
    "y_test = model.predict([x_train[0][0:4],x_train[1][0:4],x_train[2][0:4]])\n",
    "inconv_test = x_train[1][0:4]\n",
    "\n",
    "# for k in y_test.keys():\n",
    "#   y_test[k] = np.squeeze(y_test[k])\n",
    "# print(y_test)\n",
    "\n",
    "# print(y_test)\n",
    "# y_test_a = []\n",
    "# for k in y_test.keys():\n",
    "#   y_test_a.append(y_test[k])\n",
    "# y_test = np.squeeze(np.array(y_test_a))\n",
    "# print(y_test.shape)\n",
    "# print(y_test)\n",
    "\n",
    "# loss = K.eval(customLoss(K.variable([x_test,x_test,x_test]), K.variable([y_test,y_test,y_test]), K.variable([inconv_test,inconv_test,inconv_test])))\n",
    "loss = K.eval(customLoss(x_test, y_test, inconv_test))\n",
    "# print('loss shape: '    + str(loss.shape)    )\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7htvZHbENgC7"
   },
   "source": [
    "### V5 unedited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hK6jqei9Nf5W"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "#--------------------------------------------\n",
    "# Define custom loss function \n",
    "def customLoss(y_true, y_pred, invcov):\n",
    "  # print(type(y_true))    #<class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>\n",
    "\n",
    "  batch_size = tf.shape(y_pred)[0]\n",
    "  print('y_pred shape: ' + str(y_pred.shape) )  # y_pred shape is (batch, 5)\n",
    "  print('y_true shape: ' + str(y_true.shape) )  # y_true shape is (batch, 5)\n",
    "  print('invcov shape: ' + str(invcov.shape) )  # invcov shape is (batch, 25)\n",
    "  \n",
    "  y_pred = K.reshape(y_pred, (batch_size, 5,1)) # y_pred  shape is now (batch, 5,1)\n",
    "  y_true = K.reshape(y_true, (batch_size, 5,1)) # y_state shape is now (batch, 5,1)\n",
    "  invcov = K.reshape(invcov, (batch_size, 5,5)) # invcov  shape is now (batch, 5,5)\n",
    "  \n",
    "  # n.b. we must use tf.transpose here an not K.transpose since the latter does not allow perm argument\n",
    "  invcov = tf.transpose(invcov, perm=[0,2,1])     # invcov shape is now (batch, 5,5)\n",
    "  \n",
    "  # Difference between prediction and true state vectors\n",
    "  y_diff = y_pred - y_true\n",
    "\n",
    "  # n.b. use \"batch_dot\" and not \"dot\"!\n",
    "  y_dot = K.batch_dot(invcov, y_diff)           # y_dot shape is (batch,5,1)\n",
    "  y_dot = K.reshape(y_dot, (batch_size, 1, 5))  # y_dot shape is now (batch,1,5)\n",
    "  y_loss = K.batch_dot(y_dot, y_diff)           # y_loss shape is (batch,1,1)\n",
    "  y_loss = K.reshape(y_loss, (batch_size,))     # y_loss shape is now (batch)\n",
    "  # y_dict = {\n",
    "  #     \"q_pt\":y_diff[0]*y_diff[0],\n",
    "  #     \"phi\":y_diff[0]*y_diff[0]\n",
    "  # }\n",
    "  # y_diff[0] / invcov[0][0]\n",
    "  return y_loss\n",
    "\n",
    "#--------------------------------------------\n",
    "# Test loss function\n",
    "# x_test = x_train[2][0]\n",
    "# y_test = model.predict([x_train[0][0:1],x_train[1][0:1],x_train[2][0:1]])\n",
    "# y_test = np.squeeze(y_test)\n",
    "# inconv_test = x_train[1][0]\n",
    "\n",
    "# loss = K.eval(customLoss(K.variable([x_test,x_test,x_test]), K.variable([y_test,y_test,y_test]), K.variable([inconv_test,inconv_test,inconv_test])))\n",
    "# # print('loss shape: '    + str(loss.shape)    )\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4XBVGilP4tc"
   },
   "source": [
    "### V6 New Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JsGirPS0P4jb"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "def customLoss(m_invcov):\n",
    "  def customLoss_fn(y_true, y_pred):\n",
    "    batch_size = tf.shape(y_pred)[0]\n",
    "\n",
    "    y_pred = tf.cast(K.reshape(y_pred, (batch_size, 5,1)),\"float64\") # y_pred  shape is now (batch, 5,1)\n",
    "    y_true = tf.cast(K.reshape(y_true, (batch_size, 5,1)),\"float64\") # y_state shape is now (batch, 5,1)\n",
    "    invcov = tf.cast(K.reshape(m_invcov, (batch_size, 5,5)),\"float64\") # invcov  shape is now (batch, 5,5)\n",
    "    \n",
    "    # n.b. we must use tf.transpose here an not K.transpose since the latter does not allow perm argument\n",
    "    invcov = tf.transpose(invcov, perm=[0,2,1])     # invcov shape is now (batch, 5,5)\n",
    "    \n",
    "    # Difference between prediction and true state vectors\n",
    "    y_diff = y_pred - y_true\n",
    "\n",
    "    # n.b. use \"batch_dot\" and not \"dot\"!\n",
    "    y_dot = K.batch_dot(invcov, y_diff)           # y_dot shape is (batch,5,1)\n",
    "    y_dot = K.reshape(y_dot, (batch_size, 1, 5))  # y_dot shape is now (batch,1,5)\n",
    "    y_loss = K.batch_dot(y_dot, y_diff)           # y_loss shape is (batch,1,1)\n",
    "    y_loss = K.reshape(y_loss, (batch_size,))     # y_loss shape is now (batch)\n",
    "    return y_loss\n",
    "  return customLoss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rkuUUNJWjM_i"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "def customLoss(y_true, y_pred, invcov):\n",
    "  batch_size = tf.shape(y_pred)[0]\n",
    "\n",
    "  print('y_pred shape: ' + str(y_pred.shape) )  # y_pred shape is (batch, 5)\n",
    "  print('y_true shape: ' + str(y_true.shape) )  # y_true shape is (batch, 5)\n",
    "  print('invcov shape: ' + str(invcov.shape) )  # invcov shape is (batch, 25)\n",
    "\n",
    "  y_pred = tf.cast(K.reshape(y_pred, (batch_size, 5,1)),\"float64\") # y_pred  shape is now (batch, 5,1)\n",
    "  y_true = tf.cast(K.reshape(y_true, (batch_size, 5,1)),\"float64\") # y_state shape is now (batch, 5,1)\n",
    "  invcov = tf.cast(K.reshape(invcov, (batch_size, 5,5)),\"float64\") # invcov  shape is now (batch, 5,5)\n",
    "  \n",
    "  # n.b. we must use tf.transpose here an not K.transpose since the latter does not allow perm argument\n",
    "  invcov = tf.transpose(invcov, perm=[0,2,1])     # invcov shape is now (batch, 5,5)\n",
    "  \n",
    "  # Difference between prediction and true state vectors\n",
    "  y_diff = y_pred - y_true\n",
    "\n",
    "  # n.b. use \"batch_dot\" and not \"dot\"!\n",
    "  y_dot = K.batch_dot(invcov, y_diff)           # y_dot shape is (batch,5,1)\n",
    "  y_dot = K.reshape(y_dot, (batch_size, 1, 5))  # y_dot shape is now (batch,1,5)\n",
    "  y_loss = K.batch_dot(y_dot, y_diff)           # y_loss shape is (batch,1,1)\n",
    "  y_loss = K.reshape(y_loss, (batch_size,))     # y_loss shape is now (batch)\n",
    "  return y_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqNp5hG98yPr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "DBknRRcl6LMm"
   ],
   "name": "CopyOfRNN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
